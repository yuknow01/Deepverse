{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a20cdba8",
   "metadata": {},
   "source": [
    "#  Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee541051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a0c35af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as  np\n",
    "from lwm_model import lwm  # 클래스 import\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset as TorchDataset, DataLoader, Subset\n",
    "import time\n",
    "import torch.nn as nn\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from deepverse import ParameterManager\n",
    "from deepverse.scenario import ScenarioManager\n",
    "from deepverse import Dataset\n",
    "\n",
    "from deepverse.visualizers import ImageVisualizer, LidarVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2babd3da",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenes 2000\n",
    "## Subcarriers 64\n",
    "\n",
    "scenarios_name = \"DT31\"\n",
    "config_path = f\"scenarios/{scenarios_name}/param/config.m\"\n",
    "param_manager = ParameterManager(config_path)\n",
    "\n",
    "params = param_manager.get_params()\n",
    "\n",
    "param_manager.params[\"scenes\"] =list(range(100))\n",
    "param_manager.params[\"comm\"][\"OFDM\"][\"selected_subcarriers\"] = list(range(64))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04d7ca8",
   "metadata": {},
   "source": [
    "# Generate a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a9d341a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating camera dataset: ⏳ In progress\n",
      "\u001b[F\u001b[KGenerating camera dataset: ✅ Completed (0.00s)\n",
      "Generating LiDAR dataset: ⏳ In progress\n",
      "\u001b[F\u001b[KGenerating LiDAR dataset: ✅ Completed (0.00s)\n",
      "Generating mobility dataset: ⏳ In progress\n",
      "\u001b[F\u001b[KGenerating mobility dataset: ✅ Completed (0.00s)\n",
      "Generating comm dataset: ⏳ In progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[F\u001b[KGenerating comm dataset: ✅ Completed (1.92s)\n",
      "Generating radar dataset: ⏳ In progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[F\u001b[KGenerating radar dataset: ✅ Completed (227.51s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(param_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e0fe9a",
   "metadata": {},
   "source": [
    "# location dataset \n",
    " 지금 실험에서는 안쓰임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6db8cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comm = dataset.comm_dataset\n",
    "# location =  comm\n",
    "\n",
    "# location = [\n",
    "#     {\n",
    "#         \"bs_loc\": d[\"bs_loc\"],                      # (3,)\n",
    "#         \"ue_loc\": np.asarray(d[\"ue_loc\"]).squeeze() # (3,)  (원래 (1,3)이면 squeeze)\n",
    "#     }\n",
    "#     for row in comm.data      # row: [dict] 형태\n",
    "#     for d in row              # d: dict\n",
    "# ]\n",
    "\n",
    "# print(ue_location)  #)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a4fe58",
   "metadata": {},
   "source": [
    "# communication  dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "715162f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 16, 64)\n"
     ]
    }
   ],
   "source": [
    "# UE 정보\n",
    "comm = dataset.comm_dataset\n",
    "ch = comm.data[0][0]['ue'][0]\n",
    "print(ch.coeffs.shape)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b0f7be",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c4e21952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coeffs_from_frame(frame, ue_idx=0):\n",
    "    ue_obj = frame[\"ue\"]\n",
    "\n",
    "    # 케이스1) list/tuple이면 ue_idx로 선택\n",
    "    if isinstance(ue_obj, (list, tuple)):\n",
    "        ch_obj = ue_obj[ue_idx]\n",
    "    else:\n",
    "        # 케이스2) 단일 OFDMChannel이면 그대로 사용\n",
    "        ch_obj = ue_obj\n",
    "\n",
    "    # coeffs는 dict key가 아니라 attribute일 확률이 매우 큼\n",
    "    if hasattr(ch_obj, \"coeffs\"):\n",
    "        return ch_obj.coeffs\n",
    "\n",
    "    # 혹시 dict라면 마지막 보험\n",
    "    if isinstance(ch_obj, dict) and \"coeffs\" in ch_obj:\n",
    "        return ch_obj[\"coeffs\"]\n",
    "\n",
    "    raise TypeError(f\"Cannot get coeffs. ue type={type(ue_obj)}, ch type={type(ch_obj)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7cce7c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_min_max_realimag(frames, train_idx, us_idx=0):\n",
    "\n",
    "    rmin, rmax =  float('inf'), float('-inf')\n",
    "    imin, imax =  float('inf'), float('-inf')\n",
    "\n",
    "    print(\"Calculating min/max over training set...\")\n",
    "\n",
    "    for t  in train_idx:\n",
    "        frame  = frames[t]\n",
    "        coeffs  = get_coeffs_from_frame(frame, us_idx)  # (N_subcarriers, )\n",
    "\n",
    "        rmin = min(rmin, float(coeffs.real.min()))\n",
    "        rmax = max(rmax, float(coeffs.real.max()))\n",
    "        imin = min(imin, float(coeffs.imag.min()))\n",
    "        imax = max(imax, float(coeffs.imag.max()))\n",
    "\n",
    "    print(f\"Done. rmin={rmin}, rmax={rmax}, imin={imin}, imax={imax}\")\n",
    "    return (rmin, rmax), (imin, imax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2cb0542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps  1e-12 -> 1e-23으로 변경\n",
    "# 실제 값을 보면 r_min의 경우 −0.0000010915750361793117 이런 값이 됨\n",
    "def preprocess_channel_coeffs_minmax(coeffs_np, r_min, r_max, i_min, i_max, device=\"cuda\", eps=1e-23):\n",
    "    # Convert Numpy to Tensor\n",
    "    coeffs = torch.from_numpy(coeffs_np).to(torch.complex64)\n",
    "    \n",
    "    r = coeffs.real\n",
    "    i = coeffs.imag\n",
    "    \n",
    "    # Min-Max Scaling [0, 1]\n",
    "    # Add eps to denominator to prevent division by zero\n",
    "    r_scaled = (r - r_min) / max(r_max - r_min, eps)\n",
    "    i_scaled = (i - i_min) / max(i_max - i_min, eps)\n",
    "    \n",
    "    # Concat (Maintains shape like (..., 2*subcarriers))\n",
    "    H = torch.cat([r_scaled, i_scaled], dim=-1).to(device)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "639969a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 128])\n"
     ]
    }
   ],
   "source": [
    "# 사용예시\n",
    "H = preprocess_channel_coeffs_minmax(ch.coeffs, r_min=-0.5, r_max=0.5, i_min=-0.5, i_max=0.5)\n",
    "print(H.shape)  # (1, 16, 128) 64 subcar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37a4765",
   "metadata": {},
   "source": [
    "# Dataset 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "faab47e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_comm_frames(comm):\n",
    "    frames = []\n",
    "    for row in comm.data:\n",
    "        for d in row:\n",
    "            frames.append(d)\n",
    "    return frames\n",
    "\n",
    "class ChannelNextStepDatasetGPU(TorchDataset):\n",
    "    def __init__(self, comm_frames, ue_idx=0, past_len=16, device=\"cuda\",\n",
    "                 r_min=0.0, r_max=1.0, i_min=0.0, i_max=1.0):\n",
    "        self.comm_frames = comm_frames\n",
    "        self.ue_idx = ue_idx\n",
    "        self.past_len = past_len\n",
    "        self.device = device\n",
    "\n",
    "        self.r_min, self.r_max = r_min, r_max\n",
    "        self.i_min, self.i_max = i_min, i_max\n",
    "\n",
    "        self.N = len(self.comm_frames)\n",
    "        self.valid_start = past_len - 1\n",
    "        self.valid_end = self.N - 2\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.valid_end - self.valid_start + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        t = self.valid_start + idx\n",
    "\n",
    "        # 1) Channel Past\n",
    "        ch_list = []\n",
    "        for k in range(t - self.past_len + 1, t + 1):\n",
    "            coeffs_np = get_coeffs_from_frame(self.comm_frames[k], ue_idx=self.ue_idx)\n",
    "            h = preprocess_channel_coeffs_minmax(\n",
    "                coeffs_np,\n",
    "                self.r_min, self.r_max, self.i_min, self.i_max,\n",
    "                device=self.device\n",
    "            ).reshape(-1)\n",
    "            ch_list.append(h)\n",
    "        channel_past = torch.stack(ch_list, dim=0)  # (T, F_in)\n",
    "\n",
    "        # 2) Target (next step)\n",
    "        coeffs_np_next = get_coeffs_from_frame(self.comm_frames[t + 1], ue_idx=self.ue_idx)\n",
    "        target = preprocess_channel_coeffs_minmax(\n",
    "            coeffs_np_next,\n",
    "            self.r_min, self.r_max, self.i_min, self.i_max,\n",
    "            device=self.device\n",
    "        ).reshape(-1)  # (F_out)\n",
    "\n",
    "        return channel_past, target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e24ae3c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "629d15c1",
   "metadata": {},
   "source": [
    "# DataLoader 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c940a7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 15, 2048]) torch.Size([8, 2048])\n",
      "cuda:0 cuda:0\n"
     ]
    }
   ],
   "source": [
    "comm_frames = flatten_comm_frames(dataset.comm_dataset)\n",
    "\n",
    "ds = ChannelNextStepDatasetGPU(\n",
    "    comm_frames=comm_frames,\n",
    "    ue_idx=0,\n",
    "    past_len=15,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "loader = DataLoader(\n",
    "    ds,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0,     \n",
    "    pin_memory=False   # ✅ 의미 없음 (이미 GPU)\n",
    ")\n",
    "\n",
    "ch, y = next(iter(loader))\n",
    "print(ch.shape,  y.shape)\n",
    "print(ch.device, y.device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d24e5ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch shape: torch.Size([8, 15, 2048]) y shape: torch.Size([8, 2048])\n",
      "ch[0, -1, :20] = tensor([ 1.3230e-07,  1.1461e-07,  9.1956e-08,  6.1297e-08,  2.1578e-08,\n",
      "        -2.5845e-08, -7.7558e-08, -1.2910e-07, -1.7628e-07, -2.1633e-07,\n",
      "        -2.4846e-07, -2.7380e-07, -2.9455e-07, -3.1292e-07, -3.3013e-07,\n",
      "        -3.4589e-07, -3.5862e-07, -3.6620e-07, -3.6703e-07, -3.6095e-07],\n",
      "       device='cuda:0')\n",
      "y[0, :20] = tensor([-4.2879e-07, -4.0625e-07, -3.7814e-07, -3.4526e-07, -3.0989e-07,\n",
      "        -2.7518e-07, -2.4410e-07, -2.1836e-07, -1.9763e-07, -1.7952e-07,\n",
      "        -1.6023e-07, -1.3567e-07, -1.0283e-07, -6.0708e-08, -1.0651e-08,\n",
      "         4.4064e-08,  9.9264e-08,  1.5113e-07,  1.9726e-07,  2.3710e-07],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "ch, y = next(iter(loader))  # or train_loader\n",
    "\n",
    "print(\"ch shape:\", ch.shape, \"y shape:\", y.shape)\n",
    "\n",
    "# 첫 샘플, 마지막 타임스텝, 앞 20개 값만 보기\n",
    "print(\"ch[0, -1, :20] =\", ch[0, -1, :20])\n",
    "\n",
    "# 첫 샘플 타깃 벡터 앞 20개\n",
    "print(\"y[0, :20] =\", y[0, :20])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e613ac09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch min/max: -1.5673900861656875e-06 1.5746156805107603e-06\n",
      "y  min/max: -9.961363502952736e-07 1.0209263336946606e-06\n",
      "ch mean/std: -3.420363992034936e-09 4.5454865471583616e-07\n",
      "y  mean/std: -9.203304784932698e-11 3.6898541111440863e-07\n"
     ]
    }
   ],
   "source": [
    "print(\"ch min/max:\", ch.min().item(), ch.max().item())\n",
    "print(\"y  min/max:\", y.min().item(),  y.max().item())\n",
    "\n",
    "print(\"ch mean/std:\", ch.mean().item(), ch.std().item())\n",
    "print(\"y  mean/std:\", y.mean().item(),  y.std().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "109bf542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_now shape: (1, 16, 64) dtype: complex128\n",
      "raw_now real min/max: -1.0915750361793117e-06 1.1047814353805472e-06\n",
      "raw_now imag min/max: -1.1138026455803887e-06 1.1093295598083908e-06\n",
      "raw_next real min/max: -1.0288621162405502e-06 1.0310415144220829e-06\n",
      "raw_next imag min/max: -1.0319768287920318e-06 1.0419675883991902e-06\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "channel_past, target = ds[idx]  # 이미 스케일링 된 텐서\n",
    "\n",
    "t = ds.valid_start + idx\n",
    "\n",
    "raw_now  = get_coeffs_from_frame(comm_frames[t], ue_idx=0)      # numpy complex\n",
    "raw_next = get_coeffs_from_frame(comm_frames[t+1], ue_idx=0)\n",
    "\n",
    "print(\"raw_now shape:\", raw_now.shape, \"dtype:\", raw_now.dtype)\n",
    "print(\"raw_now real min/max:\", raw_now.real.min(), raw_now.real.max())\n",
    "print(\"raw_now imag min/max:\", raw_now.imag.min(), raw_now.imag.max())\n",
    "\n",
    "print(\"raw_next real min/max:\", raw_next.real.min(), raw_next.real.max())\n",
    "print(\"raw_next imag min/max:\", raw_next.imag.min(), raw_next.imag.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb2511a",
   "metadata": {},
   "source": [
    "# Fine-tuning\n",
    "data shape 맞추기 위해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1c529263",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LWMForecasterNoEdit(nn.Module):\n",
    "    \"\"\"\n",
    "    lwm 코드는 수정하지 않고, encoder(embedding+layers)만 직접 호출해서 forecasting\n",
    "    Input : ch  (B,T,F_in)\n",
    "    Output: yhat(B,F_out)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,      \n",
    "            base_lwm: nn.Module,\n",
    "            F_in: int,\n",
    "            F_out: int,\n",
    "            pool=\"last\",\n",
    "            freeze_backbone: bool = False,\n",
    "            element_length: int = 16,\n",
    "            d_model: int = 64\n",
    "            ):\n",
    "        super().__init__()\n",
    "        self.base = base_lwm\n",
    "        self.pool = pool\n",
    "\n",
    "        n_dim = self.base.embedding.element_length  # = ELEMENT_LENGTH(16)\n",
    "\n",
    "        self.in_proj = nn.Sequential(\n",
    "            nn.Linear(F_in, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(128, n_dim),\n",
    "        )\n",
    "        self.head = nn.Linear(d_model, F_out)\n",
    "\n",
    "    def forward(self, ch):\n",
    "        x = self.in_proj(ch)          # (B,T,F_in) -> (B,T,16)\n",
    "\n",
    "        # ✅ lwm.forward() 쓰지 않고 encoder만 사용\n",
    "        out = self.base.embedding(x)  # (B,T,64)\n",
    "        for layer in self.base.layers:\n",
    "            out, _ = layer(out)       # (B,T,64)\n",
    "\n",
    "        if self.pool == \"last\":\n",
    "            z = out[:, -1, :]\n",
    "        elif self.pool == \"mean\":\n",
    "            z = out.mean(dim=1)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown pool={self.pool}\")\n",
    "\n",
    "        return self.head(z)           # (B,F_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a391b0",
   "metadata": {},
   "source": [
    "## NMSE(dB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c804d9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def nmse_db(yhat: torch.Tensor, y: torch.Tensor, eps: float = 1e-23  ) -> torch.Tensor:\n",
    "    # yhat, y: (B,F)\n",
    "    num = torch.sum((yhat - y) ** 2, dim=1)\n",
    "    den = torch.sum(y ** 2, dim=1).clamp_min(eps)\n",
    "    nmse = num / den\n",
    "    return 10.0 * torch.log10(nmse.clamp_min(eps)).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fdc594",
   "metadata": {},
   "source": [
    "# Train/Val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2ba34747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating min/max over training set...\n",
      "Done. rmin=-1.0915750361793117e-06, rmax=1.1047814353805472e-06, imin=-1.1138026455803887e-06, imax=1.1093295598083908e-06\n",
      "Dataset statistical values set in the dataset.\n",
      "\n",
      "=== Data Check ===\n",
      "y stats | min: 0.01882527768611908, max: 0.9940890073776245\n",
      "If scaling worked correctly, values should be within [0, 1].\n",
      "ch shape: torch.Size([32, 15, 2048]) y shape: torch.Size([32, 2048])\n"
     ]
    }
   ],
   "source": [
    "n = len(ds)\n",
    "n_train = int(0.75 * n)\n",
    "train_idx = list(range(0, n_train))\n",
    "val_idx = list(range(n_train, n))\n",
    "\n",
    "train_ts = [ds.valid_start + i for i in train_idx]\n",
    "\n",
    "# min__max scaler 적용\n",
    "(real_min,  real_max), (imag_min, imag_max) = get_train_min_max_realimag(\n",
    "    comm_frames, train_ts, us_idx=0\n",
    ")\n",
    "\n",
    "ds.r_min = real_min\n",
    "ds.r_max = real_max\n",
    "ds.i_min = imag_min\n",
    "ds.i_max = imag_max\n",
    "\n",
    "print(\"Dataset statistical values set in the dataset.\")\n",
    "\n",
    "train_ds = Subset(ds, train_idx)\n",
    "val_ds   = Subset(ds, val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,  num_workers=0)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "# Verify\n",
    "ch, y = next(iter(train_loader))\n",
    "print(\"\\n=== Data Check ===\")\n",
    "print(f\"y stats | min: {y.min().item():}, max: {y.max().item():}\")\n",
    "print(\"If scaling worked correctly, values should be within [0, 1].\")\n",
    "print(\"ch shape:\", ch.shape, \"y shape:\", y.shape)   # 추가 확인용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aa662c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bbf8fb",
   "metadata": {},
   "source": [
    "# Model generate and also check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "692cc0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "Detected: F_in= 2048 F_out= 2048\n",
      "Batch devices: cuda:0 cuda:0\n",
      "yhat: torch.Size([32, 2048]) y: torch.Size([32, 2048])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "# 배치 하나로 F_in/F_out 자동 확정 \n",
    "ch, y = next(iter(train_loader))\n",
    "F_in  = ch.shape[-1]\n",
    "F_out = y.shape[-1]\n",
    "print(\"Detected:\", \"F_in=\", F_in, \"F_out=\", F_out)\n",
    "print(\"Batch devices:\", ch.device, y.device)\n",
    "\n",
    "# --- base LWM (lwm_model은 수정 안 함) ---\n",
    "# 너가 lwm 클래스를 정의해둔 파일에서 import 되어 있어야 함\n",
    "# from lwm_model import lwm\n",
    "base = lwm(\n",
    "    element_length=16,\n",
    "    d_model=64,\n",
    "    max_len=129,\n",
    "    n_layers=12\n",
    ").to(device)\n",
    "\n",
    "# 또는 pretrained 쓰면:\n",
    "# base = lwm.from_pretrained(\"model_weights.pth\", device=device)\n",
    "\n",
    "# --- forecasting wrapper (fine-tuning 쪽에서만) ---\n",
    "model = LWMForecasterNoEdit(\n",
    "    base_lwm=base,\n",
    "    F_in=F_in,\n",
    "    F_out=F_out,\n",
    "    pool=\"last\"\n",
    ").to(device)\n",
    "\n",
    "# sanity forward\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    yhat = model(ch.to(device))\n",
    "print(\"yhat:\", yhat.shape, \"y:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5893214",
   "metadata": {},
   "source": [
    "# Train/ Eval 함수 (AMP + grad clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fb7f6957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, device, use_amp=True, grad_clip=1.0):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_nmse = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for ch, y in loader:\n",
    "        # Dataset이 이미 cuda 텐서를 반환하더라도 안전하게 유지\n",
    "        ch = ch.to(device, non_blocking=True)\n",
    "        y  = y.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "            yhat = model(ch)\n",
    "            loss = F.mse_loss(yhat, y)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if grad_clip is not None and grad_clip > 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_nmse += nmse_db(yhat.detach(), y).item()\n",
    "        n += 1\n",
    "\n",
    "    return total_loss / max(n, 1), total_nmse / max(n, 1)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_nmse = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for ch, y in loader:  \n",
    "        ch = ch.to(device, non_blocking=True)\n",
    "        y  = y.to(device, non_blocking=True)\n",
    "\n",
    "        yhat = model(ch)  \n",
    "        loss = F.mse_loss(yhat, y)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_nmse += nmse_db(yhat, y).item()\n",
    "        n += 1\n",
    "\n",
    "    return total_loss / max(n, 1), total_nmse / max(n, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84ab5d4",
   "metadata": {},
   "source": [
    "#  Optiimizer  / Scheduler 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d404b267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1853648\n"
     ]
    }
   ],
   "source": [
    "# requires_grad=True인 파라미터만 학습\n",
    "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "print(\"trainable params:\", sum(p.numel() for p in trainable_params))\n",
    "\n",
    "optimizer = torch.optim.AdamW(trainable_params, lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# (선택) cosine scheduler\n",
    "epochs = 1000\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2897236b",
   "metadata": {},
   "source": [
    "# 학습 루프 + checkpoint 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "758db97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30651/578535649.py:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
      "/tmp/ipykernel_30651/578535649.py:16: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/1000] train loss=0.597673, nmse(dB)=3.2387 | val loss=0.420491, nmse(dB)=2.1047 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[02/1000] train loss=0.428028, nmse(dB)=1.7726 | val loss=0.303385, nmse(dB)=0.6865 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[03/1000] train loss=0.326283, nmse(dB)=0.5874 | val loss=0.233207, nmse(dB)=-0.4567 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[04/1000] train loss=0.273938, nmse(dB)=-0.1829 | val loss=0.195118, nmse(dB)=-1.2318 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[05/1000] train loss=0.243138, nmse(dB)=-0.7075 | val loss=0.168227, nmse(dB)=-1.8766 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[06/1000] train loss=0.217001, nmse(dB)=-1.2101 | val loss=0.141138, nmse(dB)=-2.6404 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[07/1000] train loss=0.187942, nmse(dB)=-1.8343 | val loss=0.115264, nmse(dB)=-3.5221 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[08/1000] train loss=0.159499, nmse(dB)=-2.5733 | val loss=0.091804, nmse(dB)=-4.5143 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[09/1000] train loss=0.133922, nmse(dB)=-3.3322 | val loss=0.073191, nmse(dB)=-5.5045 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[10/1000] train loss=0.115899, nmse(dB)=-3.9748 | val loss=0.060154, nmse(dB)=-6.3649 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[11/1000] train loss=0.102086, nmse(dB)=-4.5592 | val loss=0.050811, nmse(dB)=-7.1083 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[12/1000] train loss=0.091076, nmse(dB)=-5.0788 | val loss=0.043185, nmse(dB)=-7.8285 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[13/1000] train loss=0.083538, nmse(dB)=-5.4948 | val loss=0.035998, nmse(dB)=-8.6414 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[14/1000] train loss=0.075855, nmse(dB)=-5.9356 | val loss=0.028961, nmse(dB)=-9.6274 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[15/1000] train loss=0.069657, nmse(dB)=-6.3835 | val loss=0.023041, nmse(dB)=-10.6899 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[16/1000] train loss=0.063816, nmse(dB)=-6.8176 | val loss=0.018973, nmse(dB)=-11.6265 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[17/1000] train loss=0.060801, nmse(dB)=-7.0419 | val loss=0.016674, nmse(dB)=-12.2769 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[18/1000] train loss=0.058513, nmse(dB)=-7.2517 | val loss=0.015661, nmse(dB)=-12.6008 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[19/1000] train loss=0.058461, nmse(dB)=-7.2684 | val loss=0.015302, nmse(dB)=-12.7217 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[20/1000] train loss=0.057541, nmse(dB)=-7.3266 | val loss=0.014697, nmse(dB)=-12.9384 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[21/1000] train loss=0.057607, nmse(dB)=-7.3765 | val loss=0.013969, nmse(dB)=-13.2207 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[22/1000] train loss=0.055557, nmse(dB)=-7.5361 | val loss=0.013495, nmse(dB)=-13.4183 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[23/1000] train loss=0.053867, nmse(dB)=-7.6708 | val loss=0.012987, nmse(dB)=-13.6450 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[24/1000] train loss=0.053608, nmse(dB)=-7.7034 | val loss=0.012936, nmse(dB)=-13.6727 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[25/1000] train loss=0.053356, nmse(dB)=-7.7671 | val loss=0.012931, nmse(dB)=-13.6789 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[26/1000] train loss=0.052656, nmse(dB)=-7.8167 | val loss=0.012732, nmse(dB)=-13.7654 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[27/1000] train loss=0.052232, nmse(dB)=-7.8582 | val loss=0.012479, nmse(dB)=-13.8832 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[28/1000] train loss=0.051103, nmse(dB)=-8.0000 | val loss=0.012121, nmse(dB)=-14.0606 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[29/1000] train loss=0.051091, nmse(dB)=-7.9730 | val loss=0.011806, nmse(dB)=-14.2248 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[30/1000] train loss=0.050986, nmse(dB)=-7.9973 | val loss=0.011557, nmse(dB)=-14.3644 | 1.3s\n",
      "  ↳ saved best_finetune.pt\n",
      "[31/1000] train loss=0.050153, nmse(dB)=-8.0779 | val loss=0.011419, nmse(dB)=-14.4420 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[32/1000] train loss=0.049639, nmse(dB)=-8.1296 | val loss=0.011388, nmse(dB)=-14.4582 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[33/1000] train loss=0.050421, nmse(dB)=-8.0856 | val loss=0.011149, nmse(dB)=-14.6058 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[34/1000] train loss=0.049235, nmse(dB)=-8.2046 | val loss=0.011029, nmse(dB)=-14.6791 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[35/1000] train loss=0.048913, nmse(dB)=-8.1741 | val loss=0.011106, nmse(dB)=-14.6293 | 0.2s\n",
      "[36/1000] train loss=0.048615, nmse(dB)=-8.2362 | val loss=0.011011, nmse(dB)=-14.6969 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[37/1000] train loss=0.048482, nmse(dB)=-8.3099 | val loss=0.011103, nmse(dB)=-14.6461 | 0.2s\n",
      "[38/1000] train loss=0.048195, nmse(dB)=-8.3058 | val loss=0.011154, nmse(dB)=-14.6113 | 0.2s\n",
      "[39/1000] train loss=0.047519, nmse(dB)=-8.3906 | val loss=0.011078, nmse(dB)=-14.6588 | 0.2s\n",
      "[40/1000] train loss=0.047719, nmse(dB)=-8.3276 | val loss=0.011192, nmse(dB)=-14.5814 | 0.2s\n",
      "[41/1000] train loss=0.048090, nmse(dB)=-8.3447 | val loss=0.010948, nmse(dB)=-14.7395 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[42/1000] train loss=0.047377, nmse(dB)=-8.4051 | val loss=0.010864, nmse(dB)=-14.7865 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[43/1000] train loss=0.047171, nmse(dB)=-8.4402 | val loss=0.010927, nmse(dB)=-14.7466 | 0.2s\n",
      "[44/1000] train loss=0.046598, nmse(dB)=-8.4909 | val loss=0.010812, nmse(dB)=-14.8379 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[45/1000] train loss=0.046941, nmse(dB)=-8.4718 | val loss=0.010951, nmse(dB)=-14.7447 | 0.2s\n",
      "[46/1000] train loss=0.046181, nmse(dB)=-8.5084 | val loss=0.010904, nmse(dB)=-14.7768 | 0.2s\n",
      "[47/1000] train loss=0.046296, nmse(dB)=-8.5425 | val loss=0.010764, nmse(dB)=-14.8820 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[48/1000] train loss=0.045988, nmse(dB)=-8.5574 | val loss=0.010778, nmse(dB)=-14.8649 | 0.2s\n",
      "[49/1000] train loss=0.045964, nmse(dB)=-8.5673 | val loss=0.010745, nmse(dB)=-14.8826 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[50/1000] train loss=0.045692, nmse(dB)=-8.6131 | val loss=0.010810, nmse(dB)=-14.8400 | 0.2s\n",
      "[51/1000] train loss=0.045939, nmse(dB)=-8.5840 | val loss=0.010783, nmse(dB)=-14.8590 | 0.2s\n",
      "[52/1000] train loss=0.045256, nmse(dB)=-8.6388 | val loss=0.010795, nmse(dB)=-14.8565 | 0.2s\n",
      "[53/1000] train loss=0.045328, nmse(dB)=-8.6348 | val loss=0.010836, nmse(dB)=-14.8219 | 0.2s\n",
      "[54/1000] train loss=0.045228, nmse(dB)=-8.6586 | val loss=0.010739, nmse(dB)=-14.8684 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[55/1000] train loss=0.045157, nmse(dB)=-8.6880 | val loss=0.010846, nmse(dB)=-14.8011 | 0.2s\n",
      "[56/1000] train loss=0.045193, nmse(dB)=-8.6712 | val loss=0.010758, nmse(dB)=-14.8800 | 0.2s\n",
      "[57/1000] train loss=0.045022, nmse(dB)=-8.6835 | val loss=0.010755, nmse(dB)=-14.8762 | 0.2s\n",
      "[58/1000] train loss=0.045105, nmse(dB)=-8.6932 | val loss=0.010714, nmse(dB)=-14.8937 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[59/1000] train loss=0.044810, nmse(dB)=-8.7371 | val loss=0.010810, nmse(dB)=-14.8299 | 0.2s\n",
      "[60/1000] train loss=0.045054, nmse(dB)=-8.6781 | val loss=0.010670, nmse(dB)=-14.9392 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[61/1000] train loss=0.044723, nmse(dB)=-8.7307 | val loss=0.010832, nmse(dB)=-14.8261 | 0.2s\n",
      "[62/1000] train loss=0.044721, nmse(dB)=-8.7216 | val loss=0.010718, nmse(dB)=-14.8961 | 0.2s\n",
      "[63/1000] train loss=0.044725, nmse(dB)=-8.7416 | val loss=0.010717, nmse(dB)=-14.9011 | 0.2s\n",
      "[64/1000] train loss=0.044554, nmse(dB)=-8.7305 | val loss=0.010727, nmse(dB)=-14.8855 | 0.2s\n",
      "[65/1000] train loss=0.044249, nmse(dB)=-8.7831 | val loss=0.010691, nmse(dB)=-14.9147 | 0.2s\n",
      "[66/1000] train loss=0.044211, nmse(dB)=-8.7975 | val loss=0.010697, nmse(dB)=-14.9158 | 0.2s\n",
      "[67/1000] train loss=0.044217, nmse(dB)=-8.7910 | val loss=0.010732, nmse(dB)=-14.8871 | 0.2s\n",
      "[68/1000] train loss=0.044479, nmse(dB)=-8.7777 | val loss=0.010752, nmse(dB)=-14.8673 | 0.2s\n",
      "[69/1000] train loss=0.044227, nmse(dB)=-8.8084 | val loss=0.010703, nmse(dB)=-14.9055 | 0.2s\n",
      "[70/1000] train loss=0.044305, nmse(dB)=-8.8017 | val loss=0.010708, nmse(dB)=-14.8992 | 0.2s\n",
      "[71/1000] train loss=0.044171, nmse(dB)=-8.8050 | val loss=0.010644, nmse(dB)=-14.9629 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[72/1000] train loss=0.044188, nmse(dB)=-8.8056 | val loss=0.010700, nmse(dB)=-14.9318 | 0.2s\n",
      "[73/1000] train loss=0.043987, nmse(dB)=-8.8384 | val loss=0.010674, nmse(dB)=-14.9402 | 0.2s\n",
      "[74/1000] train loss=0.043974, nmse(dB)=-8.8250 | val loss=0.010770, nmse(dB)=-14.8605 | 0.2s\n",
      "[75/1000] train loss=0.044038, nmse(dB)=-8.8409 | val loss=0.010768, nmse(dB)=-14.8581 | 0.2s\n",
      "[76/1000] train loss=0.044140, nmse(dB)=-8.8023 | val loss=0.010711, nmse(dB)=-14.9136 | 0.1s\n",
      "[77/1000] train loss=0.044022, nmse(dB)=-8.8238 | val loss=0.010758, nmse(dB)=-14.8897 | 0.1s\n",
      "[78/1000] train loss=0.043967, nmse(dB)=-8.8237 | val loss=0.010652, nmse(dB)=-14.9401 | 0.2s\n",
      "[79/1000] train loss=0.043901, nmse(dB)=-8.8567 | val loss=0.010649, nmse(dB)=-14.9446 | 0.2s\n",
      "[80/1000] train loss=0.043806, nmse(dB)=-8.8671 | val loss=0.010609, nmse(dB)=-14.9732 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[81/1000] train loss=0.043856, nmse(dB)=-8.8585 | val loss=0.010745, nmse(dB)=-14.8746 | 0.2s\n",
      "[82/1000] train loss=0.043883, nmse(dB)=-8.8613 | val loss=0.010709, nmse(dB)=-14.9033 | 0.2s\n",
      "[83/1000] train loss=0.043681, nmse(dB)=-8.8768 | val loss=0.010827, nmse(dB)=-14.8370 | 0.2s\n",
      "[84/1000] train loss=0.043664, nmse(dB)=-8.8728 | val loss=0.010797, nmse(dB)=-14.8477 | 0.1s\n",
      "[85/1000] train loss=0.043698, nmse(dB)=-8.8656 | val loss=0.010727, nmse(dB)=-14.8973 | 0.2s\n",
      "[86/1000] train loss=0.043635, nmse(dB)=-8.8757 | val loss=0.010755, nmse(dB)=-14.8750 | 0.1s\n",
      "[87/1000] train loss=0.043720, nmse(dB)=-8.8579 | val loss=0.010675, nmse(dB)=-14.9255 | 0.1s\n",
      "[88/1000] train loss=0.043514, nmse(dB)=-8.8929 | val loss=0.010708, nmse(dB)=-14.9011 | 0.2s\n",
      "[89/1000] train loss=0.043515, nmse(dB)=-8.8961 | val loss=0.010614, nmse(dB)=-14.9708 | 0.1s\n",
      "[90/1000] train loss=0.043502, nmse(dB)=-8.8958 | val loss=0.010586, nmse(dB)=-14.9872 | 0.1s\n",
      "  ↳ saved best_finetune.pt\n",
      "[91/1000] train loss=0.043375, nmse(dB)=-8.9119 | val loss=0.010641, nmse(dB)=-14.9404 | 0.1s\n",
      "[92/1000] train loss=0.043502, nmse(dB)=-8.8887 | val loss=0.010699, nmse(dB)=-14.9148 | 0.1s\n",
      "[93/1000] train loss=0.043636, nmse(dB)=-8.8851 | val loss=0.010660, nmse(dB)=-14.9472 | 0.1s\n",
      "[94/1000] train loss=0.043605, nmse(dB)=-8.8915 | val loss=0.010629, nmse(dB)=-14.9608 | 0.2s\n",
      "[95/1000] train loss=0.043569, nmse(dB)=-8.8871 | val loss=0.010768, nmse(dB)=-14.8720 | 0.1s\n",
      "[96/1000] train loss=0.043387, nmse(dB)=-8.9254 | val loss=0.010670, nmse(dB)=-14.9449 | 0.1s\n",
      "[97/1000] train loss=0.043407, nmse(dB)=-8.9027 | val loss=0.010749, nmse(dB)=-14.8949 | 0.1s\n",
      "[98/1000] train loss=0.043480, nmse(dB)=-8.8955 | val loss=0.010682, nmse(dB)=-14.9301 | 0.1s\n",
      "[99/1000] train loss=0.043244, nmse(dB)=-8.9287 | val loss=0.010709, nmse(dB)=-14.8941 | 0.2s\n",
      "[100/1000] train loss=0.043445, nmse(dB)=-8.9049 | val loss=0.010711, nmse(dB)=-14.9083 | 0.1s\n",
      "[101/1000] train loss=0.043212, nmse(dB)=-8.9337 | val loss=0.010707, nmse(dB)=-14.9177 | 0.1s\n",
      "[102/1000] train loss=0.043362, nmse(dB)=-8.9331 | val loss=0.010676, nmse(dB)=-14.9448 | 0.2s\n",
      "[103/1000] train loss=0.043269, nmse(dB)=-8.9267 | val loss=0.010706, nmse(dB)=-14.8908 | 0.1s\n",
      "[104/1000] train loss=0.043220, nmse(dB)=-8.9409 | val loss=0.010759, nmse(dB)=-14.8511 | 0.2s\n",
      "[105/1000] train loss=0.043329, nmse(dB)=-8.9205 | val loss=0.010737, nmse(dB)=-14.8873 | 0.1s\n",
      "[106/1000] train loss=0.043073, nmse(dB)=-8.9676 | val loss=0.010715, nmse(dB)=-14.9065 | 0.2s\n",
      "[107/1000] train loss=0.043098, nmse(dB)=-8.9523 | val loss=0.010718, nmse(dB)=-14.8847 | 0.1s\n",
      "[108/1000] train loss=0.043183, nmse(dB)=-8.9450 | val loss=0.010793, nmse(dB)=-14.8379 | 0.1s\n",
      "[109/1000] train loss=0.043078, nmse(dB)=-8.9524 | val loss=0.010683, nmse(dB)=-14.9384 | 0.1s\n",
      "[110/1000] train loss=0.043249, nmse(dB)=-8.9275 | val loss=0.010759, nmse(dB)=-14.9005 | 0.1s\n",
      "[111/1000] train loss=0.043300, nmse(dB)=-8.9336 | val loss=0.010718, nmse(dB)=-14.9119 | 0.2s\n",
      "[112/1000] train loss=0.043047, nmse(dB)=-8.9558 | val loss=0.010712, nmse(dB)=-14.9032 | 0.2s\n",
      "[113/1000] train loss=0.043198, nmse(dB)=-8.9319 | val loss=0.010673, nmse(dB)=-14.9290 | 0.2s\n",
      "[114/1000] train loss=0.042915, nmse(dB)=-8.9782 | val loss=0.010689, nmse(dB)=-14.9383 | 0.2s\n",
      "[115/1000] train loss=0.042848, nmse(dB)=-8.9847 | val loss=0.010638, nmse(dB)=-14.9554 | 0.2s\n",
      "[116/1000] train loss=0.043001, nmse(dB)=-8.9752 | val loss=0.010721, nmse(dB)=-14.8816 | 0.2s\n",
      "[117/1000] train loss=0.042924, nmse(dB)=-8.9831 | val loss=0.010661, nmse(dB)=-14.9507 | 0.2s\n",
      "[118/1000] train loss=0.043023, nmse(dB)=-8.9632 | val loss=0.010651, nmse(dB)=-14.9711 | 0.2s\n",
      "[119/1000] train loss=0.042969, nmse(dB)=-8.9746 | val loss=0.010773, nmse(dB)=-14.8500 | 0.2s\n",
      "[120/1000] train loss=0.043138, nmse(dB)=-8.9408 | val loss=0.010735, nmse(dB)=-14.8812 | 0.2s\n",
      "[121/1000] train loss=0.043024, nmse(dB)=-8.9705 | val loss=0.010714, nmse(dB)=-14.8861 | 0.2s\n",
      "[122/1000] train loss=0.042853, nmse(dB)=-8.9812 | val loss=0.010773, nmse(dB)=-14.8524 | 0.2s\n",
      "[123/1000] train loss=0.042991, nmse(dB)=-8.9751 | val loss=0.010724, nmse(dB)=-14.9062 | 0.2s\n",
      "[124/1000] train loss=0.042800, nmse(dB)=-8.9997 | val loss=0.010712, nmse(dB)=-14.8952 | 0.2s\n",
      "[125/1000] train loss=0.042838, nmse(dB)=-8.9997 | val loss=0.010655, nmse(dB)=-14.9110 | 0.2s\n",
      "[126/1000] train loss=0.042719, nmse(dB)=-9.0175 | val loss=0.010689, nmse(dB)=-14.9171 | 0.2s\n",
      "[127/1000] train loss=0.042785, nmse(dB)=-8.9915 | val loss=0.010641, nmse(dB)=-14.9787 | 0.2s\n",
      "[128/1000] train loss=0.042801, nmse(dB)=-8.9935 | val loss=0.010658, nmse(dB)=-14.9563 | 0.2s\n",
      "[129/1000] train loss=0.042864, nmse(dB)=-8.9988 | val loss=0.010674, nmse(dB)=-14.9300 | 0.2s\n",
      "[130/1000] train loss=0.042862, nmse(dB)=-8.9901 | val loss=0.010743, nmse(dB)=-14.8865 | 0.2s\n",
      "[131/1000] train loss=0.042741, nmse(dB)=-9.0101 | val loss=0.010714, nmse(dB)=-14.9158 | 0.2s\n",
      "[132/1000] train loss=0.042852, nmse(dB)=-8.9985 | val loss=0.010692, nmse(dB)=-14.9201 | 0.2s\n",
      "[133/1000] train loss=0.042608, nmse(dB)=-9.0102 | val loss=0.010743, nmse(dB)=-14.8787 | 0.2s\n",
      "[134/1000] train loss=0.042750, nmse(dB)=-9.0004 | val loss=0.010658, nmse(dB)=-14.9212 | 0.2s\n",
      "[135/1000] train loss=0.042769, nmse(dB)=-9.0083 | val loss=0.010655, nmse(dB)=-14.9466 | 0.2s\n",
      "[136/1000] train loss=0.042647, nmse(dB)=-9.0199 | val loss=0.010672, nmse(dB)=-14.9474 | 0.2s\n",
      "[137/1000] train loss=0.042740, nmse(dB)=-9.0126 | val loss=0.010677, nmse(dB)=-14.9246 | 0.2s\n",
      "[138/1000] train loss=0.042912, nmse(dB)=-9.0047 | val loss=0.010665, nmse(dB)=-14.9407 | 0.2s\n",
      "[139/1000] train loss=0.042774, nmse(dB)=-9.0073 | val loss=0.010605, nmse(dB)=-14.9765 | 0.2s\n",
      "[140/1000] train loss=0.042566, nmse(dB)=-9.0346 | val loss=0.010613, nmse(dB)=-14.9592 | 0.2s\n",
      "[141/1000] train loss=0.042483, nmse(dB)=-9.0513 | val loss=0.010660, nmse(dB)=-14.9295 | 0.2s\n",
      "[142/1000] train loss=0.042569, nmse(dB)=-9.0323 | val loss=0.010662, nmse(dB)=-14.9395 | 0.2s\n",
      "[143/1000] train loss=0.042526, nmse(dB)=-9.0352 | val loss=0.010701, nmse(dB)=-14.8990 | 0.2s\n",
      "[144/1000] train loss=0.042473, nmse(dB)=-9.0413 | val loss=0.010765, nmse(dB)=-14.8596 | 0.2s\n",
      "[145/1000] train loss=0.042608, nmse(dB)=-9.0348 | val loss=0.010666, nmse(dB)=-14.9501 | 0.2s\n",
      "[146/1000] train loss=0.042766, nmse(dB)=-9.0083 | val loss=0.010701, nmse(dB)=-14.9280 | 0.2s\n",
      "[147/1000] train loss=0.042599, nmse(dB)=-9.0249 | val loss=0.010653, nmse(dB)=-14.9457 | 0.2s\n",
      "[148/1000] train loss=0.042437, nmse(dB)=-9.0548 | val loss=0.010713, nmse(dB)=-14.8924 | 0.2s\n",
      "[149/1000] train loss=0.042565, nmse(dB)=-9.0449 | val loss=0.010697, nmse(dB)=-14.8973 | 0.2s\n",
      "[150/1000] train loss=0.042820, nmse(dB)=-9.0074 | val loss=0.010644, nmse(dB)=-14.9322 | 0.2s\n",
      "[151/1000] train loss=0.042486, nmse(dB)=-9.0493 | val loss=0.010690, nmse(dB)=-14.9223 | 0.2s\n",
      "[152/1000] train loss=0.042493, nmse(dB)=-9.0452 | val loss=0.010733, nmse(dB)=-14.8869 | 0.2s\n",
      "[153/1000] train loss=0.042541, nmse(dB)=-9.0256 | val loss=0.010697, nmse(dB)=-14.9217 | 0.2s\n",
      "[154/1000] train loss=0.042545, nmse(dB)=-9.0285 | val loss=0.010730, nmse(dB)=-14.9058 | 0.2s\n",
      "[155/1000] train loss=0.042367, nmse(dB)=-9.0477 | val loss=0.010668, nmse(dB)=-14.9335 | 0.2s\n",
      "[156/1000] train loss=0.042312, nmse(dB)=-9.0774 | val loss=0.010573, nmse(dB)=-15.0003 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[157/1000] train loss=0.042415, nmse(dB)=-9.0609 | val loss=0.010644, nmse(dB)=-14.9413 | 0.2s\n",
      "[158/1000] train loss=0.042569, nmse(dB)=-9.0454 | val loss=0.010637, nmse(dB)=-14.9487 | 0.2s\n",
      "[159/1000] train loss=0.042276, nmse(dB)=-9.0681 | val loss=0.010700, nmse(dB)=-14.9132 | 0.2s\n",
      "[160/1000] train loss=0.042444, nmse(dB)=-9.0452 | val loss=0.010597, nmse(dB)=-14.9862 | 0.2s\n",
      "[161/1000] train loss=0.042389, nmse(dB)=-9.0611 | val loss=0.010666, nmse(dB)=-14.9216 | 0.2s\n",
      "[162/1000] train loss=0.042466, nmse(dB)=-9.0616 | val loss=0.010625, nmse(dB)=-14.9576 | 0.2s\n",
      "[163/1000] train loss=0.042299, nmse(dB)=-9.0667 | val loss=0.010633, nmse(dB)=-14.9570 | 0.2s\n",
      "[164/1000] train loss=0.042423, nmse(dB)=-9.0535 | val loss=0.010621, nmse(dB)=-14.9738 | 0.2s\n",
      "[165/1000] train loss=0.042325, nmse(dB)=-9.0604 | val loss=0.010618, nmse(dB)=-14.9746 | 0.2s\n",
      "[166/1000] train loss=0.042362, nmse(dB)=-9.0667 | val loss=0.010672, nmse(dB)=-14.9356 | 0.2s\n",
      "[167/1000] train loss=0.042388, nmse(dB)=-9.0471 | val loss=0.010668, nmse(dB)=-14.9318 | 0.2s\n",
      "[168/1000] train loss=0.042186, nmse(dB)=-9.0866 | val loss=0.010652, nmse(dB)=-14.9345 | 0.2s\n",
      "[169/1000] train loss=0.042246, nmse(dB)=-9.0837 | val loss=0.010647, nmse(dB)=-14.9461 | 0.2s\n",
      "[170/1000] train loss=0.042406, nmse(dB)=-9.0538 | val loss=0.010708, nmse(dB)=-14.9187 | 0.2s\n",
      "[171/1000] train loss=0.042463, nmse(dB)=-9.0441 | val loss=0.010694, nmse(dB)=-14.9260 | 0.2s\n",
      "[172/1000] train loss=0.042301, nmse(dB)=-9.0645 | val loss=0.010690, nmse(dB)=-14.9328 | 0.2s\n",
      "[173/1000] train loss=0.042489, nmse(dB)=-9.0665 | val loss=0.010726, nmse(dB)=-14.8962 | 0.2s\n",
      "[174/1000] train loss=0.042157, nmse(dB)=-9.0929 | val loss=0.010701, nmse(dB)=-14.9119 | 0.2s\n",
      "[175/1000] train loss=0.042342, nmse(dB)=-9.0654 | val loss=0.010688, nmse(dB)=-14.9258 | 0.2s\n",
      "[176/1000] train loss=0.042321, nmse(dB)=-9.0755 | val loss=0.010654, nmse(dB)=-14.9318 | 0.2s\n",
      "[177/1000] train loss=0.042292, nmse(dB)=-9.0790 | val loss=0.010629, nmse(dB)=-14.9595 | 0.2s\n",
      "[178/1000] train loss=0.042461, nmse(dB)=-9.0590 | val loss=0.010631, nmse(dB)=-14.9470 | 0.2s\n",
      "[179/1000] train loss=0.042371, nmse(dB)=-9.0666 | val loss=0.010613, nmse(dB)=-14.9722 | 0.2s\n",
      "[180/1000] train loss=0.042196, nmse(dB)=-9.0785 | val loss=0.010675, nmse(dB)=-14.9190 | 0.2s\n",
      "[181/1000] train loss=0.042183, nmse(dB)=-9.0858 | val loss=0.010675, nmse(dB)=-14.9337 | 0.2s\n",
      "[182/1000] train loss=0.042177, nmse(dB)=-9.0848 | val loss=0.010656, nmse(dB)=-14.9647 | 0.2s\n",
      "[183/1000] train loss=0.042290, nmse(dB)=-9.0753 | val loss=0.010688, nmse(dB)=-14.9232 | 0.2s\n",
      "[184/1000] train loss=0.042152, nmse(dB)=-9.0924 | val loss=0.010595, nmse(dB)=-15.0002 | 0.2s\n",
      "[185/1000] train loss=0.042318, nmse(dB)=-9.0738 | val loss=0.010628, nmse(dB)=-14.9635 | 0.2s\n",
      "[186/1000] train loss=0.042155, nmse(dB)=-9.0926 | val loss=0.010751, nmse(dB)=-14.8756 | 0.2s\n",
      "[187/1000] train loss=0.042305, nmse(dB)=-9.0729 | val loss=0.010704, nmse(dB)=-14.9048 | 0.2s\n",
      "[188/1000] train loss=0.042172, nmse(dB)=-9.0986 | val loss=0.010621, nmse(dB)=-14.9607 | 0.2s\n",
      "[189/1000] train loss=0.042177, nmse(dB)=-9.0917 | val loss=0.010593, nmse(dB)=-14.9653 | 0.2s\n",
      "[190/1000] train loss=0.042159, nmse(dB)=-9.1006 | val loss=0.010656, nmse(dB)=-14.9339 | 0.2s\n",
      "[191/1000] train loss=0.042143, nmse(dB)=-9.0927 | val loss=0.010613, nmse(dB)=-14.9738 | 0.2s\n",
      "[192/1000] train loss=0.042076, nmse(dB)=-9.1034 | val loss=0.010643, nmse(dB)=-14.9503 | 0.2s\n",
      "[193/1000] train loss=0.042047, nmse(dB)=-9.1048 | val loss=0.010633, nmse(dB)=-14.9705 | 0.2s\n",
      "[194/1000] train loss=0.042231, nmse(dB)=-9.0789 | val loss=0.010706, nmse(dB)=-14.9248 | 0.2s\n",
      "[195/1000] train loss=0.042014, nmse(dB)=-9.0980 | val loss=0.010678, nmse(dB)=-14.9480 | 0.2s\n",
      "[196/1000] train loss=0.042106, nmse(dB)=-9.0957 | val loss=0.010632, nmse(dB)=-14.9592 | 0.2s\n",
      "[197/1000] train loss=0.042025, nmse(dB)=-9.1129 | val loss=0.010584, nmse(dB)=-14.9718 | 0.2s\n",
      "[198/1000] train loss=0.042029, nmse(dB)=-9.1070 | val loss=0.010577, nmse(dB)=-14.9754 | 0.2s\n",
      "[199/1000] train loss=0.042293, nmse(dB)=-9.0930 | val loss=0.010692, nmse(dB)=-14.9038 | 0.2s\n",
      "[200/1000] train loss=0.042147, nmse(dB)=-9.1019 | val loss=0.010655, nmse(dB)=-14.9345 | 0.2s\n",
      "[201/1000] train loss=0.042254, nmse(dB)=-9.0908 | val loss=0.010715, nmse(dB)=-14.9004 | 0.2s\n",
      "[202/1000] train loss=0.042105, nmse(dB)=-9.0822 | val loss=0.010635, nmse(dB)=-14.9837 | 0.2s\n",
      "[203/1000] train loss=0.042009, nmse(dB)=-9.1049 | val loss=0.010678, nmse(dB)=-14.9474 | 0.2s\n",
      "[204/1000] train loss=0.041980, nmse(dB)=-9.1076 | val loss=0.010653, nmse(dB)=-14.9529 | 0.2s\n",
      "[205/1000] train loss=0.042025, nmse(dB)=-9.1034 | val loss=0.010572, nmse(dB)=-15.0099 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[206/1000] train loss=0.042118, nmse(dB)=-9.1058 | val loss=0.010579, nmse(dB)=-15.0011 | 0.2s\n",
      "[207/1000] train loss=0.041900, nmse(dB)=-9.1214 | val loss=0.010576, nmse(dB)=-14.9810 | 0.2s\n",
      "[208/1000] train loss=0.042106, nmse(dB)=-9.1055 | val loss=0.010588, nmse(dB)=-14.9803 | 0.2s\n",
      "[209/1000] train loss=0.042040, nmse(dB)=-9.1059 | val loss=0.010631, nmse(dB)=-14.9521 | 0.2s\n",
      "[210/1000] train loss=0.042027, nmse(dB)=-9.1079 | val loss=0.010663, nmse(dB)=-14.9430 | 0.2s\n",
      "[211/1000] train loss=0.041818, nmse(dB)=-9.1301 | val loss=0.010662, nmse(dB)=-14.9347 | 0.2s\n",
      "[212/1000] train loss=0.041938, nmse(dB)=-9.1190 | val loss=0.010671, nmse(dB)=-14.9456 | 0.2s\n",
      "[213/1000] train loss=0.041997, nmse(dB)=-9.1130 | val loss=0.010630, nmse(dB)=-14.9860 | 0.2s\n",
      "[214/1000] train loss=0.041872, nmse(dB)=-9.1248 | val loss=0.010658, nmse(dB)=-14.9605 | 0.2s\n",
      "[215/1000] train loss=0.041927, nmse(dB)=-9.1239 | val loss=0.010604, nmse(dB)=-14.9931 | 0.2s\n",
      "[216/1000] train loss=0.041919, nmse(dB)=-9.1157 | val loss=0.010554, nmse(dB)=-14.9974 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[217/1000] train loss=0.041954, nmse(dB)=-9.1244 | val loss=0.010556, nmse(dB)=-14.9849 | 0.2s\n",
      "[218/1000] train loss=0.041853, nmse(dB)=-9.1293 | val loss=0.010569, nmse(dB)=-14.9999 | 0.2s\n",
      "[219/1000] train loss=0.041861, nmse(dB)=-9.1203 | val loss=0.010601, nmse(dB)=-14.9938 | 0.2s\n",
      "[220/1000] train loss=0.041813, nmse(dB)=-9.1298 | val loss=0.010607, nmse(dB)=-14.9859 | 0.2s\n",
      "[221/1000] train loss=0.041888, nmse(dB)=-9.1234 | val loss=0.010730, nmse(dB)=-14.9015 | 0.2s\n",
      "[222/1000] train loss=0.041836, nmse(dB)=-9.1238 | val loss=0.010704, nmse(dB)=-14.9078 | 0.2s\n",
      "[223/1000] train loss=0.041727, nmse(dB)=-9.1372 | val loss=0.010697, nmse(dB)=-14.9189 | 0.2s\n",
      "[224/1000] train loss=0.041857, nmse(dB)=-9.1269 | val loss=0.010684, nmse(dB)=-14.9255 | 1.3s\n",
      "[225/1000] train loss=0.041803, nmse(dB)=-9.1288 | val loss=0.010659, nmse(dB)=-14.9309 | 0.2s\n",
      "[226/1000] train loss=0.041672, nmse(dB)=-9.1480 | val loss=0.010559, nmse(dB)=-15.0117 | 0.2s\n",
      "[227/1000] train loss=0.041668, nmse(dB)=-9.1425 | val loss=0.010568, nmse(dB)=-14.9931 | 0.2s\n",
      "[228/1000] train loss=0.041636, nmse(dB)=-9.1463 | val loss=0.010586, nmse(dB)=-14.9815 | 0.2s\n",
      "[229/1000] train loss=0.041783, nmse(dB)=-9.1294 | val loss=0.010580, nmse(dB)=-15.0167 | 0.2s\n",
      "[230/1000] train loss=0.041723, nmse(dB)=-9.1368 | val loss=0.010650, nmse(dB)=-14.9504 | 0.2s\n",
      "[231/1000] train loss=0.041767, nmse(dB)=-9.1276 | val loss=0.010683, nmse(dB)=-14.9020 | 0.2s\n",
      "[232/1000] train loss=0.041528, nmse(dB)=-9.1532 | val loss=0.010696, nmse(dB)=-14.9081 | 0.2s\n",
      "[233/1000] train loss=0.041664, nmse(dB)=-9.1319 | val loss=0.010697, nmse(dB)=-14.9227 | 0.2s\n",
      "[234/1000] train loss=0.041487, nmse(dB)=-9.1414 | val loss=0.010636, nmse(dB)=-14.9686 | 0.2s\n",
      "[235/1000] train loss=0.041539, nmse(dB)=-9.1472 | val loss=0.010597, nmse(dB)=-14.9852 | 0.2s\n",
      "[236/1000] train loss=0.041460, nmse(dB)=-9.1480 | val loss=0.010722, nmse(dB)=-14.9108 | 0.2s\n",
      "[237/1000] train loss=0.041542, nmse(dB)=-9.1344 | val loss=0.010726, nmse(dB)=-14.8858 | 0.2s\n",
      "[238/1000] train loss=0.041430, nmse(dB)=-9.1521 | val loss=0.010674, nmse(dB)=-14.9115 | 0.2s\n",
      "[239/1000] train loss=0.041505, nmse(dB)=-9.1482 | val loss=0.010667, nmse(dB)=-14.9098 | 0.2s\n",
      "[240/1000] train loss=0.041593, nmse(dB)=-9.1317 | val loss=0.010801, nmse(dB)=-14.8490 | 0.2s\n",
      "[241/1000] train loss=0.041661, nmse(dB)=-9.1251 | val loss=0.010647, nmse(dB)=-14.9468 | 0.2s\n",
      "[242/1000] train loss=0.041433, nmse(dB)=-9.1488 | val loss=0.010601, nmse(dB)=-14.9850 | 0.2s\n",
      "[243/1000] train loss=0.041320, nmse(dB)=-9.1605 | val loss=0.010670, nmse(dB)=-14.9575 | 0.2s\n",
      "[244/1000] train loss=0.041485, nmse(dB)=-9.1350 | val loss=0.010620, nmse(dB)=-14.9757 | 0.2s\n",
      "[245/1000] train loss=0.041364, nmse(dB)=-9.1409 | val loss=0.010687, nmse(dB)=-14.9157 | 0.2s\n",
      "[246/1000] train loss=0.041248, nmse(dB)=-9.1592 | val loss=0.010636, nmse(dB)=-14.9511 | 0.2s\n",
      "[247/1000] train loss=0.041337, nmse(dB)=-9.1536 | val loss=0.010692, nmse(dB)=-14.9101 | 0.2s\n",
      "[248/1000] train loss=0.041563, nmse(dB)=-9.1296 | val loss=0.010684, nmse(dB)=-14.9170 | 0.2s\n",
      "[249/1000] train loss=0.041116, nmse(dB)=-9.1707 | val loss=0.010907, nmse(dB)=-14.7640 | 0.2s\n",
      "[250/1000] train loss=0.041138, nmse(dB)=-9.1648 | val loss=0.010854, nmse(dB)=-14.8159 | 0.2s\n",
      "[251/1000] train loss=0.041253, nmse(dB)=-9.1388 | val loss=0.010715, nmse(dB)=-14.8974 | 0.2s\n",
      "[252/1000] train loss=0.041157, nmse(dB)=-9.1586 | val loss=0.010772, nmse(dB)=-14.8690 | 0.2s\n",
      "[253/1000] train loss=0.041112, nmse(dB)=-9.1502 | val loss=0.011005, nmse(dB)=-14.7117 | 0.2s\n",
      "[254/1000] train loss=0.040763, nmse(dB)=-9.1669 | val loss=0.010703, nmse(dB)=-14.9181 | 0.2s\n",
      "[255/1000] train loss=0.040746, nmse(dB)=-9.1837 | val loss=0.010759, nmse(dB)=-14.8711 | 0.2s\n",
      "[256/1000] train loss=0.040691, nmse(dB)=-9.1947 | val loss=0.010782, nmse(dB)=-14.8541 | 0.2s\n",
      "[257/1000] train loss=0.040776, nmse(dB)=-9.1904 | val loss=0.010814, nmse(dB)=-14.8477 | 0.2s\n",
      "[258/1000] train loss=0.040556, nmse(dB)=-9.2017 | val loss=0.010756, nmse(dB)=-14.8616 | 0.2s\n",
      "[259/1000] train loss=0.040505, nmse(dB)=-9.2051 | val loss=0.010782, nmse(dB)=-14.8267 | 0.2s\n",
      "[260/1000] train loss=0.040522, nmse(dB)=-9.2011 | val loss=0.010665, nmse(dB)=-14.9223 | 0.2s\n",
      "[261/1000] train loss=0.040306, nmse(dB)=-9.2271 | val loss=0.010888, nmse(dB)=-14.7823 | 0.2s\n",
      "[262/1000] train loss=0.040237, nmse(dB)=-9.2156 | val loss=0.010646, nmse(dB)=-14.9313 | 0.2s\n",
      "[263/1000] train loss=0.040347, nmse(dB)=-9.2117 | val loss=0.010694, nmse(dB)=-14.8955 | 0.2s\n",
      "[264/1000] train loss=0.040014, nmse(dB)=-9.2300 | val loss=0.010783, nmse(dB)=-14.8641 | 0.2s\n",
      "[265/1000] train loss=0.040091, nmse(dB)=-9.2318 | val loss=0.010656, nmse(dB)=-14.9501 | 0.2s\n",
      "[266/1000] train loss=0.039808, nmse(dB)=-9.2490 | val loss=0.010726, nmse(dB)=-14.9030 | 0.2s\n",
      "[267/1000] train loss=0.039657, nmse(dB)=-9.2687 | val loss=0.010644, nmse(dB)=-14.9505 | 0.2s\n",
      "[268/1000] train loss=0.039674, nmse(dB)=-9.2741 | val loss=0.010769, nmse(dB)=-14.8666 | 0.2s\n",
      "[269/1000] train loss=0.039435, nmse(dB)=-9.2879 | val loss=0.010690, nmse(dB)=-14.9106 | 0.2s\n",
      "[270/1000] train loss=0.039456, nmse(dB)=-9.2780 | val loss=0.011158, nmse(dB)=-14.6027 | 0.2s\n",
      "[271/1000] train loss=0.039604, nmse(dB)=-9.2449 | val loss=0.010812, nmse(dB)=-14.8199 | 0.2s\n",
      "[272/1000] train loss=0.038952, nmse(dB)=-9.3299 | val loss=0.010863, nmse(dB)=-14.8069 | 0.2s\n",
      "[273/1000] train loss=0.039233, nmse(dB)=-9.3031 | val loss=0.010719, nmse(dB)=-14.9008 | 0.2s\n",
      "[274/1000] train loss=0.039010, nmse(dB)=-9.3268 | val loss=0.010654, nmse(dB)=-14.9367 | 0.2s\n",
      "[275/1000] train loss=0.038771, nmse(dB)=-9.3462 | val loss=0.010783, nmse(dB)=-14.8484 | 0.2s\n",
      "[276/1000] train loss=0.038698, nmse(dB)=-9.3441 | val loss=0.010686, nmse(dB)=-14.8993 | 0.2s\n",
      "[277/1000] train loss=0.038529, nmse(dB)=-9.3675 | val loss=0.010752, nmse(dB)=-14.8841 | 0.1s\n",
      "[278/1000] train loss=0.038554, nmse(dB)=-9.3611 | val loss=0.010760, nmse(dB)=-14.8493 | 0.1s\n",
      "[279/1000] train loss=0.038324, nmse(dB)=-9.3870 | val loss=0.010721, nmse(dB)=-14.8790 | 0.2s\n",
      "[280/1000] train loss=0.038034, nmse(dB)=-9.4227 | val loss=0.010779, nmse(dB)=-14.8189 | 0.1s\n",
      "[281/1000] train loss=0.038234, nmse(dB)=-9.4058 | val loss=0.010873, nmse(dB)=-14.8119 | 0.1s\n",
      "[282/1000] train loss=0.037997, nmse(dB)=-9.4132 | val loss=0.010928, nmse(dB)=-14.7128 | 0.1s\n",
      "[283/1000] train loss=0.037784, nmse(dB)=-9.4404 | val loss=0.010980, nmse(dB)=-14.7677 | 0.1s\n",
      "[284/1000] train loss=0.037740, nmse(dB)=-9.4411 | val loss=0.010746, nmse(dB)=-14.8645 | 0.2s\n",
      "[285/1000] train loss=0.037487, nmse(dB)=-9.4824 | val loss=0.010756, nmse(dB)=-14.8613 | 0.1s\n",
      "[286/1000] train loss=0.037685, nmse(dB)=-9.4546 | val loss=0.010790, nmse(dB)=-14.8503 | 0.1s\n",
      "[287/1000] train loss=0.037687, nmse(dB)=-9.4647 | val loss=0.010824, nmse(dB)=-14.7863 | 0.1s\n",
      "[288/1000] train loss=0.037386, nmse(dB)=-9.4856 | val loss=0.010748, nmse(dB)=-14.8980 | 0.1s\n",
      "[289/1000] train loss=0.037463, nmse(dB)=-9.4800 | val loss=0.010969, nmse(dB)=-14.6706 | 0.1s\n",
      "[290/1000] train loss=0.037388, nmse(dB)=-9.4878 | val loss=0.011134, nmse(dB)=-14.6694 | 0.1s\n",
      "[291/1000] train loss=0.037226, nmse(dB)=-9.5102 | val loss=0.011027, nmse(dB)=-14.6396 | 0.1s\n",
      "[292/1000] train loss=0.037225, nmse(dB)=-9.5101 | val loss=0.010963, nmse(dB)=-14.7774 | 0.1s\n",
      "[293/1000] train loss=0.037055, nmse(dB)=-9.5366 | val loss=0.010732, nmse(dB)=-14.8490 | 0.1s\n",
      "[294/1000] train loss=0.036863, nmse(dB)=-9.5681 | val loss=0.010795, nmse(dB)=-14.8420 | 0.1s\n",
      "[295/1000] train loss=0.036688, nmse(dB)=-9.5807 | val loss=0.010793, nmse(dB)=-14.8199 | 0.1s\n",
      "[296/1000] train loss=0.036655, nmse(dB)=-9.5892 | val loss=0.010764, nmse(dB)=-14.8654 | 0.1s\n",
      "[297/1000] train loss=0.036526, nmse(dB)=-9.6133 | val loss=0.010742, nmse(dB)=-14.8648 | 0.1s\n",
      "[298/1000] train loss=0.036457, nmse(dB)=-9.6188 | val loss=0.010772, nmse(dB)=-14.8813 | 0.1s\n",
      "[299/1000] train loss=0.036524, nmse(dB)=-9.6100 | val loss=0.010724, nmse(dB)=-14.8863 | 0.1s\n",
      "[300/1000] train loss=0.036323, nmse(dB)=-9.6460 | val loss=0.010726, nmse(dB)=-14.8888 | 0.1s\n",
      "[301/1000] train loss=0.036337, nmse(dB)=-9.6299 | val loss=0.010718, nmse(dB)=-14.8858 | 0.1s\n",
      "[302/1000] train loss=0.036175, nmse(dB)=-9.6563 | val loss=0.010666, nmse(dB)=-14.9251 | 0.1s\n",
      "[303/1000] train loss=0.036191, nmse(dB)=-9.6676 | val loss=0.010699, nmse(dB)=-14.9045 | 0.1s\n",
      "[304/1000] train loss=0.036231, nmse(dB)=-9.6714 | val loss=0.010663, nmse(dB)=-14.9311 | 0.1s\n",
      "[305/1000] train loss=0.036100, nmse(dB)=-9.6704 | val loss=0.010664, nmse(dB)=-14.9075 | 0.1s\n",
      "[306/1000] train loss=0.036210, nmse(dB)=-9.6633 | val loss=0.010668, nmse(dB)=-14.9371 | 0.1s\n",
      "[307/1000] train loss=0.035967, nmse(dB)=-9.7016 | val loss=0.010726, nmse(dB)=-14.9024 | 0.1s\n",
      "[308/1000] train loss=0.035919, nmse(dB)=-9.7038 | val loss=0.010713, nmse(dB)=-14.8595 | 0.1s\n",
      "[309/1000] train loss=0.035909, nmse(dB)=-9.7023 | val loss=0.010819, nmse(dB)=-14.8488 | 0.1s\n",
      "[310/1000] train loss=0.035832, nmse(dB)=-9.7024 | val loss=0.010748, nmse(dB)=-14.8746 | 0.1s\n",
      "[311/1000] train loss=0.035959, nmse(dB)=-9.6908 | val loss=0.010665, nmse(dB)=-14.9441 | 0.1s\n",
      "[312/1000] train loss=0.035709, nmse(dB)=-9.7269 | val loss=0.010716, nmse(dB)=-14.9151 | 0.2s\n",
      "[313/1000] train loss=0.035647, nmse(dB)=-9.7387 | val loss=0.010648, nmse(dB)=-14.9238 | 0.2s\n",
      "[314/1000] train loss=0.035685, nmse(dB)=-9.7336 | val loss=0.010686, nmse(dB)=-14.9176 | 0.2s\n",
      "[315/1000] train loss=0.035548, nmse(dB)=-9.7613 | val loss=0.010603, nmse(dB)=-14.9898 | 0.2s\n",
      "[316/1000] train loss=0.035434, nmse(dB)=-9.7722 | val loss=0.010676, nmse(dB)=-14.9137 | 0.2s\n",
      "[317/1000] train loss=0.035468, nmse(dB)=-9.7551 | val loss=0.010657, nmse(dB)=-14.9424 | 0.2s\n",
      "[318/1000] train loss=0.035421, nmse(dB)=-9.7759 | val loss=0.010679, nmse(dB)=-14.9180 | 0.2s\n",
      "[319/1000] train loss=0.035548, nmse(dB)=-9.7533 | val loss=0.010703, nmse(dB)=-14.9092 | 0.2s\n",
      "[320/1000] train loss=0.035376, nmse(dB)=-9.7613 | val loss=0.010768, nmse(dB)=-14.8778 | 0.2s\n",
      "[321/1000] train loss=0.035203, nmse(dB)=-9.7798 | val loss=0.010679, nmse(dB)=-14.9150 | 0.2s\n",
      "[322/1000] train loss=0.035333, nmse(dB)=-9.7603 | val loss=0.010842, nmse(dB)=-14.8309 | 0.2s\n",
      "[323/1000] train loss=0.035334, nmse(dB)=-9.7553 | val loss=0.010737, nmse(dB)=-14.8521 | 0.2s\n",
      "[324/1000] train loss=0.035195, nmse(dB)=-9.7735 | val loss=0.010640, nmse(dB)=-14.9427 | 0.2s\n",
      "[325/1000] train loss=0.035173, nmse(dB)=-9.7888 | val loss=0.010677, nmse(dB)=-14.9336 | 0.2s\n",
      "[326/1000] train loss=0.035095, nmse(dB)=-9.7927 | val loss=0.010764, nmse(dB)=-14.8460 | 0.2s\n",
      "[327/1000] train loss=0.035031, nmse(dB)=-9.7982 | val loss=0.010687, nmse(dB)=-14.9281 | 0.2s\n",
      "[328/1000] train loss=0.034956, nmse(dB)=-9.8052 | val loss=0.010697, nmse(dB)=-14.9261 | 0.2s\n",
      "[329/1000] train loss=0.034915, nmse(dB)=-9.8009 | val loss=0.010733, nmse(dB)=-14.8665 | 0.2s\n",
      "[330/1000] train loss=0.034920, nmse(dB)=-9.7949 | val loss=0.010732, nmse(dB)=-14.9066 | 0.2s\n",
      "[331/1000] train loss=0.034737, nmse(dB)=-9.8256 | val loss=0.010762, nmse(dB)=-14.8704 | 0.2s\n",
      "[332/1000] train loss=0.034663, nmse(dB)=-9.8146 | val loss=0.010692, nmse(dB)=-14.8956 | 0.2s\n",
      "[333/1000] train loss=0.034797, nmse(dB)=-9.7959 | val loss=0.010797, nmse(dB)=-14.8498 | 0.2s\n",
      "[334/1000] train loss=0.034463, nmse(dB)=-9.8363 | val loss=0.010620, nmse(dB)=-14.9686 | 0.2s\n",
      "[335/1000] train loss=0.034552, nmse(dB)=-9.8160 | val loss=0.010738, nmse(dB)=-14.8966 | 0.2s\n",
      "[336/1000] train loss=0.034427, nmse(dB)=-9.8505 | val loss=0.010661, nmse(dB)=-14.9206 | 0.2s\n",
      "[337/1000] train loss=0.034496, nmse(dB)=-9.8229 | val loss=0.010703, nmse(dB)=-14.9000 | 0.2s\n",
      "[338/1000] train loss=0.034448, nmse(dB)=-9.8322 | val loss=0.010875, nmse(dB)=-14.7978 | 0.2s\n",
      "[339/1000] train loss=0.034334, nmse(dB)=-9.8361 | val loss=0.010661, nmse(dB)=-14.9147 | 0.2s\n",
      "[340/1000] train loss=0.034235, nmse(dB)=-9.8459 | val loss=0.010909, nmse(dB)=-14.7494 | 0.2s\n",
      "[341/1000] train loss=0.034198, nmse(dB)=-9.8473 | val loss=0.010671, nmse(dB)=-14.9309 | 0.2s\n",
      "[342/1000] train loss=0.033966, nmse(dB)=-9.8886 | val loss=0.010672, nmse(dB)=-14.9325 | 0.2s\n",
      "[343/1000] train loss=0.034069, nmse(dB)=-9.8638 | val loss=0.010700, nmse(dB)=-14.9133 | 0.2s\n",
      "[344/1000] train loss=0.033869, nmse(dB)=-9.8856 | val loss=0.010792, nmse(dB)=-14.8771 | 0.2s\n",
      "[345/1000] train loss=0.033847, nmse(dB)=-9.8791 | val loss=0.010762, nmse(dB)=-14.8383 | 0.2s\n",
      "[346/1000] train loss=0.033672, nmse(dB)=-9.8937 | val loss=0.010713, nmse(dB)=-14.8786 | 0.2s\n",
      "[347/1000] train loss=0.033562, nmse(dB)=-9.9173 | val loss=0.010990, nmse(dB)=-14.7531 | 0.2s\n",
      "[348/1000] train loss=0.033440, nmse(dB)=-9.9091 | val loss=0.010717, nmse(dB)=-14.8823 | 0.2s\n",
      "[349/1000] train loss=0.033581, nmse(dB)=-9.8789 | val loss=0.010756, nmse(dB)=-14.8738 | 0.2s\n",
      "[350/1000] train loss=0.033278, nmse(dB)=-9.9303 | val loss=0.010720, nmse(dB)=-14.8902 | 0.2s\n",
      "[351/1000] train loss=0.033109, nmse(dB)=-9.9365 | val loss=0.010748, nmse(dB)=-14.8695 | 0.2s\n",
      "[352/1000] train loss=0.033111, nmse(dB)=-9.9488 | val loss=0.011033, nmse(dB)=-14.7009 | 0.2s\n",
      "[353/1000] train loss=0.033110, nmse(dB)=-9.9422 | val loss=0.010716, nmse(dB)=-14.8777 | 0.2s\n",
      "[354/1000] train loss=0.032871, nmse(dB)=-9.9578 | val loss=0.010813, nmse(dB)=-14.8154 | 0.2s\n",
      "[355/1000] train loss=0.032755, nmse(dB)=-9.9501 | val loss=0.010853, nmse(dB)=-14.8209 | 0.2s\n",
      "[356/1000] train loss=0.032629, nmse(dB)=-9.9775 | val loss=0.010787, nmse(dB)=-14.8255 | 0.2s\n",
      "[357/1000] train loss=0.032493, nmse(dB)=-9.9904 | val loss=0.010673, nmse(dB)=-14.9290 | 0.2s\n",
      "[358/1000] train loss=0.032349, nmse(dB)=-9.9912 | val loss=0.010721, nmse(dB)=-14.9019 | 0.2s\n",
      "[359/1000] train loss=0.032024, nmse(dB)=-10.0310 | val loss=0.010697, nmse(dB)=-14.9080 | 0.2s\n",
      "[360/1000] train loss=0.031967, nmse(dB)=-10.0358 | val loss=0.010714, nmse(dB)=-14.9295 | 0.2s\n",
      "[361/1000] train loss=0.031925, nmse(dB)=-10.0320 | val loss=0.010680, nmse(dB)=-14.9196 | 0.2s\n",
      "[362/1000] train loss=0.031683, nmse(dB)=-10.0666 | val loss=0.010777, nmse(dB)=-14.8435 | 0.2s\n",
      "[363/1000] train loss=0.031323, nmse(dB)=-10.1035 | val loss=0.010856, nmse(dB)=-14.8110 | 0.2s\n",
      "[364/1000] train loss=0.031246, nmse(dB)=-10.0994 | val loss=0.010632, nmse(dB)=-14.9658 | 0.2s\n",
      "[365/1000] train loss=0.030999, nmse(dB)=-10.1248 | val loss=0.010750, nmse(dB)=-14.8552 | 0.2s\n",
      "[366/1000] train loss=0.030929, nmse(dB)=-10.1211 | val loss=0.010887, nmse(dB)=-14.7939 | 0.2s\n",
      "[367/1000] train loss=0.030673, nmse(dB)=-10.1599 | val loss=0.010731, nmse(dB)=-14.8788 | 0.2s\n",
      "[368/1000] train loss=0.030514, nmse(dB)=-10.1648 | val loss=0.010738, nmse(dB)=-14.8756 | 0.2s\n",
      "[369/1000] train loss=0.030302, nmse(dB)=-10.1882 | val loss=0.010772, nmse(dB)=-14.8675 | 0.2s\n",
      "[370/1000] train loss=0.030186, nmse(dB)=-10.1990 | val loss=0.010734, nmse(dB)=-14.9024 | 0.2s\n",
      "[371/1000] train loss=0.030117, nmse(dB)=-10.2038 | val loss=0.010727, nmse(dB)=-14.8940 | 0.2s\n",
      "[372/1000] train loss=0.029950, nmse(dB)=-10.2105 | val loss=0.010727, nmse(dB)=-14.8930 | 0.2s\n",
      "[373/1000] train loss=0.029576, nmse(dB)=-10.2551 | val loss=0.010718, nmse(dB)=-14.8990 | 0.2s\n",
      "[374/1000] train loss=0.029567, nmse(dB)=-10.2625 | val loss=0.010686, nmse(dB)=-14.9177 | 0.2s\n",
      "[375/1000] train loss=0.029062, nmse(dB)=-10.3108 | val loss=0.010625, nmse(dB)=-14.9472 | 0.2s\n",
      "[376/1000] train loss=0.028828, nmse(dB)=-10.3483 | val loss=0.010665, nmse(dB)=-14.9381 | 0.2s\n",
      "[377/1000] train loss=0.028705, nmse(dB)=-10.3554 | val loss=0.010667, nmse(dB)=-14.9275 | 0.2s\n",
      "[378/1000] train loss=0.028712, nmse(dB)=-10.3557 | val loss=0.010655, nmse(dB)=-14.9432 | 0.2s\n",
      "[379/1000] train loss=0.028411, nmse(dB)=-10.3862 | val loss=0.010825, nmse(dB)=-14.8315 | 0.2s\n",
      "[380/1000] train loss=0.027979, nmse(dB)=-10.4538 | val loss=0.010739, nmse(dB)=-14.8753 | 0.2s\n",
      "[381/1000] train loss=0.028006, nmse(dB)=-10.4353 | val loss=0.010749, nmse(dB)=-14.8550 | 0.2s\n",
      "[382/1000] train loss=0.027807, nmse(dB)=-10.4562 | val loss=0.010621, nmse(dB)=-14.9816 | 0.2s\n",
      "[383/1000] train loss=0.027451, nmse(dB)=-10.5146 | val loss=0.010672, nmse(dB)=-14.9317 | 0.2s\n",
      "[384/1000] train loss=0.027438, nmse(dB)=-10.5028 | val loss=0.010670, nmse(dB)=-14.9183 | 0.2s\n",
      "[385/1000] train loss=0.027349, nmse(dB)=-10.4999 | val loss=0.010732, nmse(dB)=-14.8911 | 0.2s\n",
      "[386/1000] train loss=0.026999, nmse(dB)=-10.5653 | val loss=0.010690, nmse(dB)=-14.9169 | 0.2s\n",
      "[387/1000] train loss=0.026932, nmse(dB)=-10.5722 | val loss=0.010708, nmse(dB)=-14.9334 | 0.2s\n",
      "[388/1000] train loss=0.026697, nmse(dB)=-10.5958 | val loss=0.010754, nmse(dB)=-14.8716 | 0.2s\n",
      "[389/1000] train loss=0.026406, nmse(dB)=-10.6533 | val loss=0.010645, nmse(dB)=-14.9511 | 0.2s\n",
      "[390/1000] train loss=0.026188, nmse(dB)=-10.6795 | val loss=0.010712, nmse(dB)=-14.9081 | 0.2s\n",
      "[391/1000] train loss=0.026000, nmse(dB)=-10.6988 | val loss=0.010649, nmse(dB)=-14.9133 | 0.2s\n",
      "[392/1000] train loss=0.025779, nmse(dB)=-10.7441 | val loss=0.010754, nmse(dB)=-14.8437 | 0.2s\n",
      "[393/1000] train loss=0.025655, nmse(dB)=-10.7624 | val loss=0.010848, nmse(dB)=-14.8200 | 0.2s\n",
      "[394/1000] train loss=0.025589, nmse(dB)=-10.7670 | val loss=0.010840, nmse(dB)=-14.8013 | 0.2s\n",
      "[395/1000] train loss=0.025602, nmse(dB)=-10.7346 | val loss=0.010826, nmse(dB)=-14.8110 | 0.2s\n",
      "[396/1000] train loss=0.025215, nmse(dB)=-10.8244 | val loss=0.010877, nmse(dB)=-14.7908 | 0.2s\n",
      "[397/1000] train loss=0.025172, nmse(dB)=-10.8209 | val loss=0.010882, nmse(dB)=-14.7703 | 0.2s\n",
      "[398/1000] train loss=0.025170, nmse(dB)=-10.8140 | val loss=0.011288, nmse(dB)=-14.5452 | 0.2s\n",
      "[399/1000] train loss=0.025085, nmse(dB)=-10.8175 | val loss=0.010827, nmse(dB)=-14.8508 | 0.2s\n",
      "[400/1000] train loss=0.025032, nmse(dB)=-10.8342 | val loss=0.010924, nmse(dB)=-14.7706 | 0.2s\n",
      "[401/1000] train loss=0.024623, nmse(dB)=-10.9067 | val loss=0.010749, nmse(dB)=-14.8516 | 0.2s\n",
      "[402/1000] train loss=0.024327, nmse(dB)=-10.9817 | val loss=0.010664, nmse(dB)=-14.9469 | 0.2s\n",
      "[403/1000] train loss=0.024083, nmse(dB)=-11.0135 | val loss=0.010613, nmse(dB)=-14.9765 | 0.2s\n",
      "[404/1000] train loss=0.023944, nmse(dB)=-11.0429 | val loss=0.010843, nmse(dB)=-14.8209 | 0.2s\n",
      "[405/1000] train loss=0.024115, nmse(dB)=-10.9916 | val loss=0.010685, nmse(dB)=-14.9310 | 0.2s\n",
      "[406/1000] train loss=0.023723, nmse(dB)=-11.0699 | val loss=0.010579, nmse(dB)=-14.9954 | 0.2s\n",
      "[407/1000] train loss=0.023665, nmse(dB)=-11.0818 | val loss=0.010992, nmse(dB)=-14.7159 | 0.2s\n",
      "[408/1000] train loss=0.023690, nmse(dB)=-11.0688 | val loss=0.010761, nmse(dB)=-14.8523 | 0.2s\n",
      "[409/1000] train loss=0.023494, nmse(dB)=-11.1163 | val loss=0.010753, nmse(dB)=-14.8724 | 0.2s\n",
      "[410/1000] train loss=0.023222, nmse(dB)=-11.1739 | val loss=0.010552, nmse(dB)=-15.0436 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[411/1000] train loss=0.023030, nmse(dB)=-11.2137 | val loss=0.010623, nmse(dB)=-14.9898 | 0.2s\n",
      "[412/1000] train loss=0.022963, nmse(dB)=-11.2339 | val loss=0.010851, nmse(dB)=-14.7898 | 0.2s\n",
      "[413/1000] train loss=0.023008, nmse(dB)=-11.2212 | val loss=0.010712, nmse(dB)=-14.8808 | 0.2s\n",
      "[414/1000] train loss=0.022871, nmse(dB)=-11.2411 | val loss=0.010866, nmse(dB)=-14.8014 | 0.2s\n",
      "[415/1000] train loss=0.022814, nmse(dB)=-11.2422 | val loss=0.010572, nmse(dB)=-14.9815 | 0.2s\n",
      "[416/1000] train loss=0.022567, nmse(dB)=-11.3057 | val loss=0.010662, nmse(dB)=-14.9147 | 0.2s\n",
      "[417/1000] train loss=0.022554, nmse(dB)=-11.3125 | val loss=0.010844, nmse(dB)=-14.8181 | 0.2s\n",
      "[418/1000] train loss=0.022358, nmse(dB)=-11.3468 | val loss=0.011004, nmse(dB)=-14.7185 | 0.2s\n",
      "[419/1000] train loss=0.022320, nmse(dB)=-11.3578 | val loss=0.010850, nmse(dB)=-14.8210 | 0.2s\n",
      "[420/1000] train loss=0.022346, nmse(dB)=-11.3398 | val loss=0.010843, nmse(dB)=-14.8261 | 0.2s\n",
      "[421/1000] train loss=0.022154, nmse(dB)=-11.4025 | val loss=0.010663, nmse(dB)=-14.9481 | 0.2s\n",
      "[422/1000] train loss=0.021893, nmse(dB)=-11.4647 | val loss=0.010591, nmse(dB)=-15.0125 | 0.2s\n",
      "[423/1000] train loss=0.021919, nmse(dB)=-11.4366 | val loss=0.010636, nmse(dB)=-14.9513 | 0.2s\n",
      "[424/1000] train loss=0.021829, nmse(dB)=-11.4716 | val loss=0.010652, nmse(dB)=-14.9526 | 0.2s\n",
      "[425/1000] train loss=0.021668, nmse(dB)=-11.5147 | val loss=0.010692, nmse(dB)=-14.9236 | 0.2s\n",
      "[426/1000] train loss=0.021598, nmse(dB)=-11.5238 | val loss=0.010948, nmse(dB)=-14.7110 | 0.2s\n",
      "[427/1000] train loss=0.021799, nmse(dB)=-11.4659 | val loss=0.010866, nmse(dB)=-14.8097 | 0.2s\n",
      "[428/1000] train loss=0.021570, nmse(dB)=-11.5390 | val loss=0.011141, nmse(dB)=-14.5993 | 0.2s\n",
      "[429/1000] train loss=0.021766, nmse(dB)=-11.5046 | val loss=0.010951, nmse(dB)=-14.7559 | 1.3s\n",
      "[430/1000] train loss=0.021633, nmse(dB)=-11.5266 | val loss=0.010654, nmse(dB)=-14.9169 | 0.2s\n",
      "[431/1000] train loss=0.021422, nmse(dB)=-11.5747 | val loss=0.010538, nmse(dB)=-15.0200 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[432/1000] train loss=0.021094, nmse(dB)=-11.6534 | val loss=0.010605, nmse(dB)=-15.0129 | 0.2s\n",
      "[433/1000] train loss=0.021088, nmse(dB)=-11.6453 | val loss=0.010716, nmse(dB)=-14.9076 | 0.2s\n",
      "[434/1000] train loss=0.020933, nmse(dB)=-11.6905 | val loss=0.010556, nmse(dB)=-15.0324 | 0.2s\n",
      "[435/1000] train loss=0.021121, nmse(dB)=-11.6411 | val loss=0.010609, nmse(dB)=-14.9881 | 0.2s\n",
      "[436/1000] train loss=0.020827, nmse(dB)=-11.7195 | val loss=0.010805, nmse(dB)=-14.8502 | 0.2s\n",
      "[437/1000] train loss=0.020799, nmse(dB)=-11.7082 | val loss=0.010648, nmse(dB)=-14.9807 | 0.2s\n",
      "[438/1000] train loss=0.020815, nmse(dB)=-11.7289 | val loss=0.010585, nmse(dB)=-15.0019 | 0.2s\n",
      "[439/1000] train loss=0.020727, nmse(dB)=-11.7274 | val loss=0.010640, nmse(dB)=-14.9482 | 0.2s\n",
      "[440/1000] train loss=0.020512, nmse(dB)=-11.7965 | val loss=0.010502, nmse(dB)=-15.0565 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[441/1000] train loss=0.020511, nmse(dB)=-11.8048 | val loss=0.010699, nmse(dB)=-14.9164 | 0.2s\n",
      "[442/1000] train loss=0.020448, nmse(dB)=-11.8212 | val loss=0.010607, nmse(dB)=-14.9740 | 0.2s\n",
      "[443/1000] train loss=0.020318, nmse(dB)=-11.8592 | val loss=0.010672, nmse(dB)=-14.9104 | 0.2s\n",
      "[444/1000] train loss=0.020195, nmse(dB)=-11.8845 | val loss=0.010648, nmse(dB)=-14.9693 | 0.2s\n",
      "[445/1000] train loss=0.020277, nmse(dB)=-11.8488 | val loss=0.010625, nmse(dB)=-14.9685 | 0.2s\n",
      "[446/1000] train loss=0.020226, nmse(dB)=-11.8671 | val loss=0.010649, nmse(dB)=-14.9684 | 0.2s\n",
      "[447/1000] train loss=0.020064, nmse(dB)=-11.9184 | val loss=0.010553, nmse(dB)=-15.0265 | 0.2s\n",
      "[448/1000] train loss=0.019968, nmse(dB)=-11.9423 | val loss=0.010614, nmse(dB)=-14.9816 | 0.2s\n",
      "[449/1000] train loss=0.019971, nmse(dB)=-11.9373 | val loss=0.010595, nmse(dB)=-14.9965 | 0.2s\n",
      "[450/1000] train loss=0.020114, nmse(dB)=-11.9099 | val loss=0.010532, nmse(dB)=-15.0419 | 0.2s\n",
      "[451/1000] train loss=0.019860, nmse(dB)=-11.9640 | val loss=0.010647, nmse(dB)=-14.9527 | 0.2s\n",
      "[452/1000] train loss=0.019939, nmse(dB)=-11.9586 | val loss=0.010717, nmse(dB)=-14.8790 | 0.2s\n",
      "[453/1000] train loss=0.019676, nmse(dB)=-12.0244 | val loss=0.010674, nmse(dB)=-14.9436 | 0.2s\n",
      "[454/1000] train loss=0.019558, nmse(dB)=-12.0689 | val loss=0.010613, nmse(dB)=-14.9697 | 0.2s\n",
      "[455/1000] train loss=0.019560, nmse(dB)=-12.0622 | val loss=0.010559, nmse(dB)=-15.0254 | 0.2s\n",
      "[456/1000] train loss=0.019461, nmse(dB)=-12.0851 | val loss=0.010605, nmse(dB)=-14.9869 | 0.2s\n",
      "[457/1000] train loss=0.019328, nmse(dB)=-12.1287 | val loss=0.010561, nmse(dB)=-15.0298 | 0.2s\n",
      "[458/1000] train loss=0.019336, nmse(dB)=-12.1003 | val loss=0.010535, nmse(dB)=-15.0381 | 0.2s\n",
      "[459/1000] train loss=0.019367, nmse(dB)=-12.1086 | val loss=0.010543, nmse(dB)=-15.0333 | 0.2s\n",
      "[460/1000] train loss=0.019163, nmse(dB)=-12.1681 | val loss=0.010524, nmse(dB)=-15.0514 | 0.2s\n",
      "[461/1000] train loss=0.019161, nmse(dB)=-12.1613 | val loss=0.010533, nmse(dB)=-15.0308 | 0.2s\n",
      "[462/1000] train loss=0.019114, nmse(dB)=-12.1831 | val loss=0.010546, nmse(dB)=-15.0374 | 0.2s\n",
      "[463/1000] train loss=0.019075, nmse(dB)=-12.1864 | val loss=0.010755, nmse(dB)=-14.8601 | 0.2s\n",
      "[464/1000] train loss=0.019085, nmse(dB)=-12.2059 | val loss=0.010645, nmse(dB)=-14.9786 | 0.2s\n",
      "[465/1000] train loss=0.018992, nmse(dB)=-12.2275 | val loss=0.010646, nmse(dB)=-14.9639 | 0.2s\n",
      "[466/1000] train loss=0.018921, nmse(dB)=-12.2444 | val loss=0.010496, nmse(dB)=-15.0579 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[467/1000] train loss=0.018813, nmse(dB)=-12.2664 | val loss=0.010489, nmse(dB)=-15.0675 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[468/1000] train loss=0.018675, nmse(dB)=-12.2875 | val loss=0.010485, nmse(dB)=-15.0763 | 0.2s\n",
      "  ↳ saved best_finetune.pt\n",
      "[469/1000] train loss=0.018692, nmse(dB)=-12.3119 | val loss=0.010530, nmse(dB)=-15.0251 | 0.2s\n",
      "[470/1000] train loss=0.018603, nmse(dB)=-12.3409 | val loss=0.010722, nmse(dB)=-14.8854 | 0.2s\n",
      "[471/1000] train loss=0.018454, nmse(dB)=-12.3968 | val loss=0.010577, nmse(dB)=-15.0070 | 0.2s\n",
      "[472/1000] train loss=0.018533, nmse(dB)=-12.3855 | val loss=0.010622, nmse(dB)=-14.9528 | 0.2s\n",
      "[473/1000] train loss=0.018530, nmse(dB)=-12.3804 | val loss=0.010568, nmse(dB)=-15.0060 | 0.2s\n",
      "[474/1000] train loss=0.018365, nmse(dB)=-12.4319 | val loss=0.010545, nmse(dB)=-15.0366 | 0.2s\n",
      "[475/1000] train loss=0.018238, nmse(dB)=-12.4451 | val loss=0.010536, nmse(dB)=-15.0386 | 0.2s\n",
      "[476/1000] train loss=0.018380, nmse(dB)=-12.4169 | val loss=0.010506, nmse(dB)=-15.0646 | 0.2s\n",
      "[477/1000] train loss=0.018194, nmse(dB)=-12.4532 | val loss=0.010636, nmse(dB)=-14.9678 | 0.2s\n",
      "[478/1000] train loss=0.018162, nmse(dB)=-12.4698 | val loss=0.010549, nmse(dB)=-15.0155 | 0.2s\n",
      "[479/1000] train loss=0.018098, nmse(dB)=-12.4814 | val loss=0.010532, nmse(dB)=-15.0177 | 0.2s\n",
      "[480/1000] train loss=0.018128, nmse(dB)=-12.4790 | val loss=0.010529, nmse(dB)=-15.0459 | 0.2s\n",
      "[481/1000] train loss=0.017916, nmse(dB)=-12.5242 | val loss=0.010530, nmse(dB)=-15.0372 | 0.1s\n",
      "[482/1000] train loss=0.017897, nmse(dB)=-12.5422 | val loss=0.010591, nmse(dB)=-14.9950 | 0.2s\n",
      "[483/1000] train loss=0.018118, nmse(dB)=-12.4856 | val loss=0.010548, nmse(dB)=-15.0276 | 0.1s\n",
      "[484/1000] train loss=0.017885, nmse(dB)=-12.5516 | val loss=0.010618, nmse(dB)=-14.9652 | 0.1s\n",
      "[485/1000] train loss=0.017704, nmse(dB)=-12.6201 | val loss=0.010583, nmse(dB)=-15.0077 | 0.2s\n",
      "[486/1000] train loss=0.017627, nmse(dB)=-12.6511 | val loss=0.010694, nmse(dB)=-14.9251 | 0.1s\n",
      "[487/1000] train loss=0.017711, nmse(dB)=-12.5852 | val loss=0.010545, nmse(dB)=-15.0355 | 0.1s\n",
      "[488/1000] train loss=0.017678, nmse(dB)=-12.6043 | val loss=0.010664, nmse(dB)=-14.9350 | 0.2s\n",
      "[489/1000] train loss=0.017567, nmse(dB)=-12.6579 | val loss=0.010596, nmse(dB)=-14.9624 | 0.2s\n",
      "[490/1000] train loss=0.017487, nmse(dB)=-12.6471 | val loss=0.010641, nmse(dB)=-14.9528 | 0.2s\n",
      "[491/1000] train loss=0.017597, nmse(dB)=-12.6524 | val loss=0.010653, nmse(dB)=-14.9444 | 0.2s\n",
      "[492/1000] train loss=0.017316, nmse(dB)=-12.7230 | val loss=0.010584, nmse(dB)=-14.9846 | 0.2s\n",
      "[493/1000] train loss=0.017312, nmse(dB)=-12.7067 | val loss=0.010653, nmse(dB)=-14.9439 | 0.1s\n",
      "[494/1000] train loss=0.017354, nmse(dB)=-12.6975 | val loss=0.010627, nmse(dB)=-14.9767 | 0.2s\n",
      "[495/1000] train loss=0.017289, nmse(dB)=-12.7404 | val loss=0.010626, nmse(dB)=-14.9585 | 0.2s\n",
      "[496/1000] train loss=0.017243, nmse(dB)=-12.7073 | val loss=0.010729, nmse(dB)=-14.9243 | 0.2s\n",
      "[497/1000] train loss=0.017157, nmse(dB)=-12.7877 | val loss=0.010852, nmse(dB)=-14.8151 | 0.1s\n",
      "[498/1000] train loss=0.017076, nmse(dB)=-12.8459 | val loss=0.010738, nmse(dB)=-14.8858 | 0.2s\n",
      "[499/1000] train loss=0.017251, nmse(dB)=-12.7153 | val loss=0.010826, nmse(dB)=-14.8370 | 0.1s\n",
      "[500/1000] train loss=0.017112, nmse(dB)=-12.7810 | val loss=0.010642, nmse(dB)=-14.9362 | 0.1s\n",
      "[501/1000] train loss=0.017063, nmse(dB)=-12.8250 | val loss=0.010578, nmse(dB)=-14.9783 | 0.2s\n",
      "[502/1000] train loss=0.017142, nmse(dB)=-12.8003 | val loss=0.010686, nmse(dB)=-14.9225 | 0.1s\n",
      "[503/1000] train loss=0.016834, nmse(dB)=-12.9345 | val loss=0.010598, nmse(dB)=-14.9833 | 0.2s\n",
      "[504/1000] train loss=0.016959, nmse(dB)=-12.8712 | val loss=0.010685, nmse(dB)=-14.9012 | 0.2s\n",
      "[505/1000] train loss=0.016910, nmse(dB)=-12.8340 | val loss=0.010594, nmse(dB)=-14.9781 | 0.1s\n",
      "[506/1000] train loss=0.016657, nmse(dB)=-12.9329 | val loss=0.010765, nmse(dB)=-14.8739 | 0.1s\n",
      "[507/1000] train loss=0.016605, nmse(dB)=-12.9583 | val loss=0.010659, nmse(dB)=-14.9526 | 0.2s\n",
      "[508/1000] train loss=0.016661, nmse(dB)=-12.9069 | val loss=0.010604, nmse(dB)=-14.9965 | 0.2s\n",
      "[509/1000] train loss=0.016567, nmse(dB)=-12.9642 | val loss=0.010708, nmse(dB)=-14.9121 | 0.2s\n",
      "[510/1000] train loss=0.016494, nmse(dB)=-12.9736 | val loss=0.010560, nmse(dB)=-15.0254 | 0.2s\n",
      "[511/1000] train loss=0.016564, nmse(dB)=-12.9479 | val loss=0.010592, nmse(dB)=-14.9799 | 0.2s\n",
      "[512/1000] train loss=0.016266, nmse(dB)=-13.0783 | val loss=0.010647, nmse(dB)=-14.9514 | 0.2s\n",
      "[513/1000] train loss=0.016343, nmse(dB)=-13.0271 | val loss=0.010535, nmse(dB)=-15.0398 | 0.2s\n",
      "[514/1000] train loss=0.016258, nmse(dB)=-13.0627 | val loss=0.010546, nmse(dB)=-15.0155 | 0.2s\n",
      "[515/1000] train loss=0.016162, nmse(dB)=-13.1010 | val loss=0.010587, nmse(dB)=-15.0010 | 0.2s\n",
      "[516/1000] train loss=0.016083, nmse(dB)=-13.0929 | val loss=0.010572, nmse(dB)=-15.0219 | 0.2s\n",
      "[517/1000] train loss=0.016004, nmse(dB)=-13.1545 | val loss=0.010563, nmse(dB)=-15.0154 | 0.2s\n",
      "[518/1000] train loss=0.015927, nmse(dB)=-13.2189 | val loss=0.010573, nmse(dB)=-15.0125 | 0.2s\n",
      "[519/1000] train loss=0.016054, nmse(dB)=-13.1454 | val loss=0.010563, nmse(dB)=-15.0035 | 0.2s\n",
      "[520/1000] train loss=0.015974, nmse(dB)=-13.1441 | val loss=0.010560, nmse(dB)=-14.9882 | 0.2s\n",
      "[521/1000] train loss=0.015905, nmse(dB)=-13.1841 | val loss=0.010559, nmse(dB)=-14.9966 | 0.2s\n",
      "[522/1000] train loss=0.015825, nmse(dB)=-13.1823 | val loss=0.010576, nmse(dB)=-14.9833 | 0.2s\n",
      "[523/1000] train loss=0.015716, nmse(dB)=-13.2635 | val loss=0.010556, nmse(dB)=-15.0157 | 0.2s\n",
      "[524/1000] train loss=0.015885, nmse(dB)=-13.1752 | val loss=0.010573, nmse(dB)=-14.9940 | 0.2s\n",
      "[525/1000] train loss=0.015614, nmse(dB)=-13.3128 | val loss=0.010573, nmse(dB)=-15.0003 | 0.2s\n",
      "[526/1000] train loss=0.015729, nmse(dB)=-13.2641 | val loss=0.010567, nmse(dB)=-14.9801 | 0.2s\n",
      "[527/1000] train loss=0.015559, nmse(dB)=-13.2996 | val loss=0.010576, nmse(dB)=-14.9830 | 0.2s\n",
      "[528/1000] train loss=0.015559, nmse(dB)=-13.2644 | val loss=0.010563, nmse(dB)=-15.0223 | 0.2s\n",
      "[529/1000] train loss=0.015603, nmse(dB)=-13.2725 | val loss=0.010578, nmse(dB)=-15.0074 | 0.2s\n",
      "[530/1000] train loss=0.015506, nmse(dB)=-13.3188 | val loss=0.010634, nmse(dB)=-14.9449 | 0.2s\n",
      "[531/1000] train loss=0.015443, nmse(dB)=-13.3361 | val loss=0.010525, nmse(dB)=-15.0189 | 0.2s\n",
      "[532/1000] train loss=0.015400, nmse(dB)=-13.3859 | val loss=0.010570, nmse(dB)=-15.0120 | 0.2s\n",
      "[533/1000] train loss=0.015325, nmse(dB)=-13.3606 | val loss=0.010682, nmse(dB)=-14.9237 | 0.2s\n",
      "[534/1000] train loss=0.015404, nmse(dB)=-13.3281 | val loss=0.010631, nmse(dB)=-14.9394 | 0.2s\n",
      "[535/1000] train loss=0.015227, nmse(dB)=-13.4349 | val loss=0.010654, nmse(dB)=-14.9172 | 0.2s\n",
      "[536/1000] train loss=0.015285, nmse(dB)=-13.3623 | val loss=0.010567, nmse(dB)=-14.9807 | 0.2s\n",
      "[537/1000] train loss=0.015125, nmse(dB)=-13.4314 | val loss=0.010613, nmse(dB)=-14.9736 | 0.2s\n",
      "[538/1000] train loss=0.015173, nmse(dB)=-13.4203 | val loss=0.010720, nmse(dB)=-14.9059 | 0.2s\n",
      "[539/1000] train loss=0.015249, nmse(dB)=-13.3786 | val loss=0.010738, nmse(dB)=-14.8700 | 0.2s\n",
      "[540/1000] train loss=0.015081, nmse(dB)=-13.4305 | val loss=0.010702, nmse(dB)=-14.9007 | 0.2s\n",
      "[541/1000] train loss=0.015075, nmse(dB)=-13.4523 | val loss=0.010699, nmse(dB)=-14.8935 | 0.2s\n",
      "[542/1000] train loss=0.015041, nmse(dB)=-13.4869 | val loss=0.010670, nmse(dB)=-14.9286 | 0.2s\n",
      "[543/1000] train loss=0.014928, nmse(dB)=-13.5211 | val loss=0.010806, nmse(dB)=-14.8242 | 0.2s\n",
      "[544/1000] train loss=0.014926, nmse(dB)=-13.4887 | val loss=0.010690, nmse(dB)=-14.9389 | 0.2s\n",
      "[545/1000] train loss=0.014818, nmse(dB)=-13.5731 | val loss=0.010602, nmse(dB)=-14.9775 | 0.2s\n",
      "[546/1000] train loss=0.014884, nmse(dB)=-13.5078 | val loss=0.010669, nmse(dB)=-14.9475 | 0.2s\n",
      "[547/1000] train loss=0.014758, nmse(dB)=-13.5516 | val loss=0.010800, nmse(dB)=-14.8201 | 0.2s\n",
      "[548/1000] train loss=0.014786, nmse(dB)=-13.5416 | val loss=0.010745, nmse(dB)=-14.8979 | 0.2s\n",
      "[549/1000] train loss=0.014696, nmse(dB)=-13.5818 | val loss=0.010795, nmse(dB)=-14.8232 | 0.2s\n",
      "[550/1000] train loss=0.014548, nmse(dB)=-13.6319 | val loss=0.010654, nmse(dB)=-14.9452 | 0.2s\n",
      "[551/1000] train loss=0.014533, nmse(dB)=-13.6778 | val loss=0.010591, nmse(dB)=-14.9680 | 0.2s\n",
      "[552/1000] train loss=0.014498, nmse(dB)=-13.6619 | val loss=0.010649, nmse(dB)=-14.9249 | 0.2s\n",
      "[553/1000] train loss=0.014340, nmse(dB)=-13.7041 | val loss=0.010679, nmse(dB)=-14.8711 | 0.2s\n",
      "[554/1000] train loss=0.014361, nmse(dB)=-13.7365 | val loss=0.010664, nmse(dB)=-14.9040 | 0.2s\n",
      "[555/1000] train loss=0.014397, nmse(dB)=-13.6961 | val loss=0.010626, nmse(dB)=-14.9766 | 0.2s\n",
      "[556/1000] train loss=0.014339, nmse(dB)=-13.7253 | val loss=0.010648, nmse(dB)=-14.9456 | 0.2s\n",
      "[557/1000] train loss=0.014178, nmse(dB)=-13.7856 | val loss=0.010676, nmse(dB)=-14.9431 | 0.2s\n",
      "[558/1000] train loss=0.014118, nmse(dB)=-13.7739 | val loss=0.010686, nmse(dB)=-14.9243 | 0.2s\n",
      "[559/1000] train loss=0.014174, nmse(dB)=-13.7684 | val loss=0.010731, nmse(dB)=-14.8766 | 0.2s\n",
      "[560/1000] train loss=0.014041, nmse(dB)=-13.7882 | val loss=0.010840, nmse(dB)=-14.7775 | 0.2s\n",
      "[561/1000] train loss=0.014068, nmse(dB)=-13.7981 | val loss=0.010683, nmse(dB)=-14.9287 | 0.2s\n",
      "[562/1000] train loss=0.014059, nmse(dB)=-13.8169 | val loss=0.010672, nmse(dB)=-14.9030 | 0.2s\n",
      "[563/1000] train loss=0.013965, nmse(dB)=-13.8299 | val loss=0.010717, nmse(dB)=-14.8916 | 0.2s\n",
      "[564/1000] train loss=0.014008, nmse(dB)=-13.8082 | val loss=0.010779, nmse(dB)=-14.8163 | 0.2s\n",
      "[565/1000] train loss=0.013878, nmse(dB)=-13.8581 | val loss=0.010799, nmse(dB)=-14.8586 | 0.2s\n",
      "[566/1000] train loss=0.013884, nmse(dB)=-13.8340 | val loss=0.010873, nmse(dB)=-14.7484 | 0.2s\n",
      "[567/1000] train loss=0.014002, nmse(dB)=-13.7997 | val loss=0.010701, nmse(dB)=-14.9331 | 0.2s\n",
      "[568/1000] train loss=0.013823, nmse(dB)=-13.8870 | val loss=0.010675, nmse(dB)=-14.9345 | 0.2s\n",
      "[569/1000] train loss=0.013794, nmse(dB)=-13.8638 | val loss=0.010740, nmse(dB)=-14.9079 | 0.2s\n",
      "[570/1000] train loss=0.013820, nmse(dB)=-13.8746 | val loss=0.010794, nmse(dB)=-14.7879 | 0.2s\n",
      "[571/1000] train loss=0.013789, nmse(dB)=-13.8656 | val loss=0.010724, nmse(dB)=-14.9090 | 0.2s\n",
      "[572/1000] train loss=0.013657, nmse(dB)=-13.9493 | val loss=0.010827, nmse(dB)=-14.7962 | 0.2s\n",
      "[573/1000] train loss=0.013764, nmse(dB)=-13.9046 | val loss=0.010696, nmse(dB)=-14.8800 | 0.2s\n",
      "[574/1000] train loss=0.013601, nmse(dB)=-13.9456 | val loss=0.010789, nmse(dB)=-14.8446 | 0.2s\n",
      "[575/1000] train loss=0.013681, nmse(dB)=-13.9434 | val loss=0.010837, nmse(dB)=-14.7874 | 0.2s\n",
      "[576/1000] train loss=0.013528, nmse(dB)=-13.9492 | val loss=0.010847, nmse(dB)=-14.8452 | 0.2s\n",
      "[577/1000] train loss=0.013449, nmse(dB)=-14.0201 | val loss=0.010778, nmse(dB)=-14.8091 | 0.2s\n",
      "[578/1000] train loss=0.013375, nmse(dB)=-14.0188 | val loss=0.010825, nmse(dB)=-14.8365 | 0.2s\n",
      "[579/1000] train loss=0.013483, nmse(dB)=-13.9632 | val loss=0.010798, nmse(dB)=-14.8428 | 0.2s\n",
      "[580/1000] train loss=0.013393, nmse(dB)=-13.9933 | val loss=0.010822, nmse(dB)=-14.8571 | 0.2s\n",
      "[581/1000] train loss=0.013372, nmse(dB)=-13.9789 | val loss=0.011080, nmse(dB)=-14.6365 | 0.2s\n",
      "[582/1000] train loss=0.013272, nmse(dB)=-14.0537 | val loss=0.010830, nmse(dB)=-14.8628 | 0.2s\n",
      "[583/1000] train loss=0.013198, nmse(dB)=-14.0736 | val loss=0.010728, nmse(dB)=-14.8925 | 0.2s\n",
      "[584/1000] train loss=0.013168, nmse(dB)=-14.0572 | val loss=0.010669, nmse(dB)=-14.9593 | 0.2s\n",
      "[585/1000] train loss=0.013001, nmse(dB)=-14.1952 | val loss=0.010691, nmse(dB)=-14.9099 | 0.2s\n",
      "[586/1000] train loss=0.013048, nmse(dB)=-14.1233 | val loss=0.010754, nmse(dB)=-14.8396 | 0.2s\n",
      "[587/1000] train loss=0.013142, nmse(dB)=-14.0568 | val loss=0.010931, nmse(dB)=-14.7739 | 0.2s\n",
      "[588/1000] train loss=0.013062, nmse(dB)=-14.1622 | val loss=0.010931, nmse(dB)=-14.7152 | 0.2s\n",
      "[589/1000] train loss=0.013027, nmse(dB)=-14.1440 | val loss=0.011026, nmse(dB)=-14.7704 | 0.2s\n",
      "[590/1000] train loss=0.013042, nmse(dB)=-14.1292 | val loss=0.010857, nmse(dB)=-14.7782 | 0.2s\n",
      "[591/1000] train loss=0.012842, nmse(dB)=-14.2594 | val loss=0.010813, nmse(dB)=-14.8269 | 0.2s\n",
      "[592/1000] train loss=0.012889, nmse(dB)=-14.1860 | val loss=0.010690, nmse(dB)=-14.9270 | 0.2s\n",
      "[593/1000] train loss=0.012769, nmse(dB)=-14.2318 | val loss=0.010688, nmse(dB)=-14.8977 | 0.2s\n",
      "[594/1000] train loss=0.012608, nmse(dB)=-14.3253 | val loss=0.010692, nmse(dB)=-14.9135 | 0.2s\n",
      "[595/1000] train loss=0.012604, nmse(dB)=-14.2908 | val loss=0.010611, nmse(dB)=-14.9511 | 0.2s\n",
      "[596/1000] train loss=0.012515, nmse(dB)=-14.3330 | val loss=0.010605, nmse(dB)=-14.9856 | 0.2s\n",
      "[597/1000] train loss=0.012486, nmse(dB)=-14.3645 | val loss=0.010733, nmse(dB)=-14.8656 | 0.2s\n",
      "[598/1000] train loss=0.012457, nmse(dB)=-14.3609 | val loss=0.010625, nmse(dB)=-14.9674 | 0.2s\n",
      "[599/1000] train loss=0.012459, nmse(dB)=-14.3689 | val loss=0.010680, nmse(dB)=-14.9209 | 0.2s\n",
      "[600/1000] train loss=0.012438, nmse(dB)=-14.3537 | val loss=0.010644, nmse(dB)=-14.9274 | 0.2s\n",
      "[601/1000] train loss=0.012399, nmse(dB)=-14.3619 | val loss=0.010701, nmse(dB)=-14.9192 | 0.2s\n",
      "[602/1000] train loss=0.012315, nmse(dB)=-14.4224 | val loss=0.010682, nmse(dB)=-14.9186 | 0.2s\n",
      "[603/1000] train loss=0.012219, nmse(dB)=-14.4463 | val loss=0.010619, nmse(dB)=-14.9675 | 0.2s\n",
      "[604/1000] train loss=0.012205, nmse(dB)=-14.4665 | val loss=0.010619, nmse(dB)=-14.9729 | 0.2s\n",
      "[605/1000] train loss=0.012219, nmse(dB)=-14.4701 | val loss=0.010596, nmse(dB)=-14.9754 | 0.2s\n",
      "[606/1000] train loss=0.012095, nmse(dB)=-14.5330 | val loss=0.010776, nmse(dB)=-14.8904 | 0.2s\n",
      "[607/1000] train loss=0.012097, nmse(dB)=-14.5366 | val loss=0.010725, nmse(dB)=-14.8388 | 0.2s\n",
      "[608/1000] train loss=0.012093, nmse(dB)=-14.5133 | val loss=0.010640, nmse(dB)=-14.9428 | 0.2s\n",
      "[609/1000] train loss=0.012121, nmse(dB)=-14.4779 | val loss=0.010687, nmse(dB)=-14.9249 | 0.2s\n",
      "[610/1000] train loss=0.011943, nmse(dB)=-14.5964 | val loss=0.010651, nmse(dB)=-14.9303 | 0.2s\n",
      "[611/1000] train loss=0.011886, nmse(dB)=-14.6115 | val loss=0.010632, nmse(dB)=-14.9849 | 0.2s\n",
      "[612/1000] train loss=0.011914, nmse(dB)=-14.5960 | val loss=0.010586, nmse(dB)=-14.9957 | 0.2s\n",
      "[613/1000] train loss=0.011856, nmse(dB)=-14.6035 | val loss=0.010701, nmse(dB)=-14.9301 | 0.2s\n",
      "[614/1000] train loss=0.011842, nmse(dB)=-14.6101 | val loss=0.010684, nmse(dB)=-14.9416 | 0.2s\n",
      "[615/1000] train loss=0.011752, nmse(dB)=-14.6512 | val loss=0.010715, nmse(dB)=-14.8995 | 0.2s\n",
      "[616/1000] train loss=0.011822, nmse(dB)=-14.5878 | val loss=0.010601, nmse(dB)=-14.9755 | 0.2s\n",
      "[617/1000] train loss=0.011740, nmse(dB)=-14.6931 | val loss=0.010608, nmse(dB)=-14.9851 | 0.2s\n",
      "[618/1000] train loss=0.011676, nmse(dB)=-14.6545 | val loss=0.010701, nmse(dB)=-14.8810 | 0.2s\n",
      "[619/1000] train loss=0.011686, nmse(dB)=-14.6548 | val loss=0.010633, nmse(dB)=-14.9739 | 0.2s\n",
      "[620/1000] train loss=0.011649, nmse(dB)=-14.7207 | val loss=0.010619, nmse(dB)=-14.9793 | 0.2s\n",
      "[621/1000] train loss=0.011576, nmse(dB)=-14.6936 | val loss=0.010661, nmse(dB)=-14.8978 | 0.2s\n",
      "[622/1000] train loss=0.011476, nmse(dB)=-14.7790 | val loss=0.010662, nmse(dB)=-14.9635 | 0.2s\n",
      "[623/1000] train loss=0.011472, nmse(dB)=-14.8136 | val loss=0.010660, nmse(dB)=-14.9095 | 0.2s\n",
      "[624/1000] train loss=0.011479, nmse(dB)=-14.7564 | val loss=0.010651, nmse(dB)=-14.9259 | 0.2s\n",
      "[625/1000] train loss=0.011289, nmse(dB)=-14.8602 | val loss=0.010818, nmse(dB)=-14.8737 | 0.2s\n",
      "[626/1000] train loss=0.011457, nmse(dB)=-14.7514 | val loss=0.010751, nmse(dB)=-14.8733 | 0.2s\n",
      "[627/1000] train loss=0.011493, nmse(dB)=-14.7011 | val loss=0.010660, nmse(dB)=-14.9791 | 0.2s\n",
      "[628/1000] train loss=0.011395, nmse(dB)=-14.8068 | val loss=0.010618, nmse(dB)=-14.9883 | 1.3s\n",
      "[629/1000] train loss=0.011221, nmse(dB)=-14.8873 | val loss=0.010862, nmse(dB)=-14.7562 | 0.2s\n",
      "[630/1000] train loss=0.011273, nmse(dB)=-14.8621 | val loss=0.010727, nmse(dB)=-14.9082 | 0.2s\n",
      "[631/1000] train loss=0.011272, nmse(dB)=-14.8560 | val loss=0.010728, nmse(dB)=-14.9323 | 0.2s\n",
      "[632/1000] train loss=0.011117, nmse(dB)=-14.9189 | val loss=0.010669, nmse(dB)=-14.9268 | 0.2s\n",
      "[633/1000] train loss=0.011149, nmse(dB)=-14.9013 | val loss=0.010701, nmse(dB)=-14.9415 | 0.2s\n",
      "[634/1000] train loss=0.011052, nmse(dB)=-14.9006 | val loss=0.010810, nmse(dB)=-14.8750 | 0.2s\n",
      "[635/1000] train loss=0.011076, nmse(dB)=-14.9678 | val loss=0.010717, nmse(dB)=-14.8839 | 0.2s\n",
      "[636/1000] train loss=0.011077, nmse(dB)=-14.9335 | val loss=0.010609, nmse(dB)=-14.9868 | 0.2s\n",
      "[637/1000] train loss=0.010952, nmse(dB)=-14.9773 | val loss=0.010647, nmse(dB)=-14.9419 | 0.2s\n",
      "[638/1000] train loss=0.010952, nmse(dB)=-14.9576 | val loss=0.010610, nmse(dB)=-14.9628 | 0.2s\n",
      "[639/1000] train loss=0.010936, nmse(dB)=-15.0012 | val loss=0.010689, nmse(dB)=-14.9426 | 0.2s\n",
      "[640/1000] train loss=0.010798, nmse(dB)=-15.0767 | val loss=0.010688, nmse(dB)=-14.9103 | 0.2s\n",
      "[641/1000] train loss=0.010832, nmse(dB)=-15.0061 | val loss=0.010754, nmse(dB)=-14.8771 | 0.2s\n",
      "[642/1000] train loss=0.010742, nmse(dB)=-15.0499 | val loss=0.010646, nmse(dB)=-14.9571 | 0.2s\n",
      "[643/1000] train loss=0.010761, nmse(dB)=-15.0683 | val loss=0.010583, nmse(dB)=-15.0079 | 0.2s\n",
      "[644/1000] train loss=0.010699, nmse(dB)=-15.1230 | val loss=0.010704, nmse(dB)=-14.9499 | 0.2s\n",
      "[645/1000] train loss=0.010671, nmse(dB)=-15.1257 | val loss=0.010732, nmse(dB)=-14.8696 | 0.2s\n",
      "[646/1000] train loss=0.010595, nmse(dB)=-15.1170 | val loss=0.010631, nmse(dB)=-14.9703 | 0.2s\n",
      "[647/1000] train loss=0.010616, nmse(dB)=-15.0889 | val loss=0.010640, nmse(dB)=-14.9667 | 0.2s\n",
      "[648/1000] train loss=0.010589, nmse(dB)=-15.1292 | val loss=0.010570, nmse(dB)=-15.0002 | 0.2s\n",
      "[649/1000] train loss=0.010572, nmse(dB)=-15.1385 | val loss=0.010577, nmse(dB)=-14.9992 | 0.2s\n",
      "[650/1000] train loss=0.010533, nmse(dB)=-15.1651 | val loss=0.010688, nmse(dB)=-14.9610 | 0.2s\n",
      "[651/1000] train loss=0.010602, nmse(dB)=-15.1181 | val loss=0.010640, nmse(dB)=-14.9551 | 0.2s\n",
      "[652/1000] train loss=0.010447, nmse(dB)=-15.2125 | val loss=0.010653, nmse(dB)=-14.9386 | 0.2s\n",
      "[653/1000] train loss=0.010448, nmse(dB)=-15.2352 | val loss=0.010609, nmse(dB)=-14.9916 | 0.2s\n",
      "[654/1000] train loss=0.010436, nmse(dB)=-15.2203 | val loss=0.010764, nmse(dB)=-14.8410 | 0.2s\n",
      "[655/1000] train loss=0.010398, nmse(dB)=-15.2524 | val loss=0.010684, nmse(dB)=-14.9246 | 0.2s\n",
      "[656/1000] train loss=0.010393, nmse(dB)=-15.2572 | val loss=0.010612, nmse(dB)=-15.0007 | 0.2s\n",
      "[657/1000] train loss=0.010427, nmse(dB)=-15.1807 | val loss=0.010693, nmse(dB)=-14.9248 | 0.2s\n",
      "[658/1000] train loss=0.010238, nmse(dB)=-15.2763 | val loss=0.010619, nmse(dB)=-14.9714 | 0.2s\n",
      "[659/1000] train loss=0.010187, nmse(dB)=-15.3566 | val loss=0.010614, nmse(dB)=-14.9967 | 0.2s\n",
      "[660/1000] train loss=0.010127, nmse(dB)=-15.3245 | val loss=0.010528, nmse(dB)=-15.0403 | 0.2s\n",
      "[661/1000] train loss=0.010166, nmse(dB)=-15.3559 | val loss=0.010615, nmse(dB)=-15.0073 | 0.2s\n",
      "[662/1000] train loss=0.010152, nmse(dB)=-15.3473 | val loss=0.010861, nmse(dB)=-14.8055 | 0.2s\n",
      "[663/1000] train loss=0.010157, nmse(dB)=-15.3952 | val loss=0.010601, nmse(dB)=-14.9598 | 0.2s\n",
      "[664/1000] train loss=0.010043, nmse(dB)=-15.3883 | val loss=0.010587, nmse(dB)=-14.9930 | 0.2s\n",
      "[665/1000] train loss=0.009979, nmse(dB)=-15.4195 | val loss=0.010612, nmse(dB)=-14.9840 | 0.2s\n",
      "[666/1000] train loss=0.009947, nmse(dB)=-15.4278 | val loss=0.010622, nmse(dB)=-14.9900 | 0.2s\n",
      "[667/1000] train loss=0.009926, nmse(dB)=-15.4577 | val loss=0.010781, nmse(dB)=-14.9198 | 0.2s\n",
      "[668/1000] train loss=0.009999, nmse(dB)=-15.4177 | val loss=0.010730, nmse(dB)=-14.8675 | 0.2s\n",
      "[669/1000] train loss=0.009969, nmse(dB)=-15.4236 | val loss=0.010616, nmse(dB)=-14.9960 | 0.2s\n",
      "[670/1000] train loss=0.009840, nmse(dB)=-15.5271 | val loss=0.010626, nmse(dB)=-14.9707 | 0.2s\n",
      "[671/1000] train loss=0.009758, nmse(dB)=-15.5508 | val loss=0.010619, nmse(dB)=-14.9336 | 0.2s\n",
      "[672/1000] train loss=0.009773, nmse(dB)=-15.5186 | val loss=0.010752, nmse(dB)=-14.9068 | 0.2s\n",
      "[673/1000] train loss=0.009931, nmse(dB)=-15.4267 | val loss=0.010605, nmse(dB)=-15.0053 | 0.2s\n",
      "[674/1000] train loss=0.009816, nmse(dB)=-15.5280 | val loss=0.010602, nmse(dB)=-14.9652 | 0.2s\n",
      "[675/1000] train loss=0.009679, nmse(dB)=-15.5920 | val loss=0.010711, nmse(dB)=-14.9186 | 0.2s\n",
      "[676/1000] train loss=0.009718, nmse(dB)=-15.5790 | val loss=0.010601, nmse(dB)=-14.9831 | 0.2s\n",
      "[677/1000] train loss=0.009663, nmse(dB)=-15.5589 | val loss=0.010677, nmse(dB)=-14.8940 | 0.2s\n",
      "[678/1000] train loss=0.009724, nmse(dB)=-15.5672 | val loss=0.010712, nmse(dB)=-14.9428 | 0.2s\n",
      "[679/1000] train loss=0.009618, nmse(dB)=-15.6016 | val loss=0.010791, nmse(dB)=-14.8823 | 0.2s\n",
      "[680/1000] train loss=0.009674, nmse(dB)=-15.6146 | val loss=0.010701, nmse(dB)=-14.8838 | 0.2s\n",
      "[681/1000] train loss=0.009767, nmse(dB)=-15.5024 | val loss=0.010887, nmse(dB)=-14.8198 | 0.2s\n",
      "[682/1000] train loss=0.009582, nmse(dB)=-15.6015 | val loss=0.010769, nmse(dB)=-14.8711 | 0.2s\n",
      "[683/1000] train loss=0.009601, nmse(dB)=-15.5992 | val loss=0.010706, nmse(dB)=-14.9102 | 0.2s\n",
      "[684/1000] train loss=0.009535, nmse(dB)=-15.6582 | val loss=0.010873, nmse(dB)=-14.8225 | 0.2s\n",
      "[685/1000] train loss=0.009486, nmse(dB)=-15.7006 | val loss=0.010880, nmse(dB)=-14.7733 | 0.2s\n",
      "[686/1000] train loss=0.009501, nmse(dB)=-15.6610 | val loss=0.010703, nmse(dB)=-14.9335 | 0.2s\n",
      "[687/1000] train loss=0.009557, nmse(dB)=-15.6100 | val loss=0.010625, nmse(dB)=-14.9708 | 0.2s\n",
      "[688/1000] train loss=0.009373, nmse(dB)=-15.7224 | val loss=0.010841, nmse(dB)=-14.7927 | 0.2s\n",
      "[689/1000] train loss=0.009477, nmse(dB)=-15.6617 | val loss=0.010934, nmse(dB)=-14.8164 | 0.2s\n",
      "[690/1000] train loss=0.009444, nmse(dB)=-15.7151 | val loss=0.010572, nmse(dB)=-15.0037 | 0.2s\n",
      "[691/1000] train loss=0.009370, nmse(dB)=-15.7421 | val loss=0.010711, nmse(dB)=-14.9008 | 0.2s\n",
      "[692/1000] train loss=0.009420, nmse(dB)=-15.6955 | val loss=0.010968, nmse(dB)=-14.8004 | 0.2s\n",
      "[693/1000] train loss=0.009247, nmse(dB)=-15.8321 | val loss=0.010623, nmse(dB)=-14.9611 | 0.2s\n",
      "[694/1000] train loss=0.009320, nmse(dB)=-15.7933 | val loss=0.010585, nmse(dB)=-14.9946 | 0.2s\n",
      "[695/1000] train loss=0.009130, nmse(dB)=-15.8890 | val loss=0.011211, nmse(dB)=-14.6564 | 0.2s\n",
      "[696/1000] train loss=0.009263, nmse(dB)=-15.7884 | val loss=0.010772, nmse(dB)=-14.8727 | 0.2s\n",
      "[697/1000] train loss=0.009220, nmse(dB)=-15.8545 | val loss=0.010624, nmse(dB)=-14.9907 | 0.2s\n",
      "[698/1000] train loss=0.009276, nmse(dB)=-15.7682 | val loss=0.010848, nmse(dB)=-14.8879 | 0.2s\n",
      "[699/1000] train loss=0.009189, nmse(dB)=-15.8133 | val loss=0.010757, nmse(dB)=-14.8590 | 0.2s\n",
      "[700/1000] train loss=0.009110, nmse(dB)=-15.8811 | val loss=0.010740, nmse(dB)=-14.9213 | 0.2s\n",
      "[701/1000] train loss=0.009124, nmse(dB)=-15.9160 | val loss=0.010700, nmse(dB)=-14.9522 | 0.2s\n",
      "[702/1000] train loss=0.009008, nmse(dB)=-15.9145 | val loss=0.010611, nmse(dB)=-14.9530 | 0.2s\n",
      "[703/1000] train loss=0.009019, nmse(dB)=-15.9120 | val loss=0.010753, nmse(dB)=-14.9343 | 0.2s\n",
      "[704/1000] train loss=0.009083, nmse(dB)=-15.8818 | val loss=0.010618, nmse(dB)=-14.9918 | 0.2s\n",
      "[705/1000] train loss=0.008997, nmse(dB)=-15.9537 | val loss=0.010687, nmse(dB)=-14.8889 | 0.2s\n",
      "[706/1000] train loss=0.008969, nmse(dB)=-15.9670 | val loss=0.010681, nmse(dB)=-14.9802 | 0.2s\n",
      "[707/1000] train loss=0.008957, nmse(dB)=-15.9598 | val loss=0.010721, nmse(dB)=-14.9412 | 0.2s\n",
      "[708/1000] train loss=0.008921, nmse(dB)=-15.9801 | val loss=0.010660, nmse(dB)=-14.9491 | 0.2s\n",
      "[709/1000] train loss=0.008972, nmse(dB)=-15.9406 | val loss=0.010697, nmse(dB)=-14.9784 | 0.2s\n",
      "[710/1000] train loss=0.008835, nmse(dB)=-16.0276 | val loss=0.010988, nmse(dB)=-14.7611 | 0.2s\n",
      "[711/1000] train loss=0.008916, nmse(dB)=-15.9652 | val loss=0.010630, nmse(dB)=-14.9731 | 0.2s\n",
      "[712/1000] train loss=0.008828, nmse(dB)=-16.0127 | val loss=0.010783, nmse(dB)=-14.9355 | 0.2s\n",
      "[713/1000] train loss=0.008933, nmse(dB)=-15.9403 | val loss=0.010641, nmse(dB)=-15.0126 | 0.2s\n",
      "[714/1000] train loss=0.008931, nmse(dB)=-15.9168 | val loss=0.010607, nmse(dB)=-14.9709 | 0.2s\n",
      "[715/1000] train loss=0.008921, nmse(dB)=-15.9684 | val loss=0.010631, nmse(dB)=-14.9881 | 0.2s\n",
      "[716/1000] train loss=0.008740, nmse(dB)=-16.1013 | val loss=0.010909, nmse(dB)=-14.8421 | 0.2s\n",
      "[717/1000] train loss=0.008880, nmse(dB)=-15.9752 | val loss=0.010730, nmse(dB)=-14.8511 | 0.2s\n",
      "[718/1000] train loss=0.008701, nmse(dB)=-16.0950 | val loss=0.010694, nmse(dB)=-14.9563 | 0.2s\n",
      "[719/1000] train loss=0.008765, nmse(dB)=-16.0413 | val loss=0.010793, nmse(dB)=-14.9042 | 0.2s\n",
      "[720/1000] train loss=0.008682, nmse(dB)=-16.0968 | val loss=0.010632, nmse(dB)=-14.9558 | 0.2s\n",
      "[721/1000] train loss=0.008744, nmse(dB)=-16.0669 | val loss=0.010727, nmse(dB)=-14.9329 | 0.2s\n",
      "[722/1000] train loss=0.008603, nmse(dB)=-16.1406 | val loss=0.010979, nmse(dB)=-14.7987 | 0.2s\n",
      "[723/1000] train loss=0.008583, nmse(dB)=-16.1491 | val loss=0.010679, nmse(dB)=-14.9439 | 0.2s\n",
      "[724/1000] train loss=0.008740, nmse(dB)=-16.0142 | val loss=0.010707, nmse(dB)=-14.9611 | 0.2s\n",
      "[725/1000] train loss=0.008634, nmse(dB)=-16.0984 | val loss=0.010996, nmse(dB)=-14.7391 | 0.2s\n",
      "[726/1000] train loss=0.008529, nmse(dB)=-16.1922 | val loss=0.010629, nmse(dB)=-14.9580 | 0.2s\n",
      "[727/1000] train loss=0.008546, nmse(dB)=-16.1611 | val loss=0.010598, nmse(dB)=-14.9926 | 0.2s\n",
      "[728/1000] train loss=0.008594, nmse(dB)=-16.0824 | val loss=0.010873, nmse(dB)=-14.8524 | 0.2s\n",
      "[729/1000] train loss=0.008546, nmse(dB)=-16.1958 | val loss=0.010739, nmse(dB)=-14.9382 | 0.1s\n",
      "[730/1000] train loss=0.008429, nmse(dB)=-16.2626 | val loss=0.010781, nmse(dB)=-14.9260 | 0.2s\n",
      "[731/1000] train loss=0.008588, nmse(dB)=-16.1603 | val loss=0.010629, nmse(dB)=-14.9877 | 0.2s\n",
      "[732/1000] train loss=0.008417, nmse(dB)=-16.2503 | val loss=0.010726, nmse(dB)=-14.8921 | 0.2s\n",
      "[733/1000] train loss=0.008480, nmse(dB)=-16.1873 | val loss=0.010701, nmse(dB)=-14.9468 | 0.1s\n",
      "[734/1000] train loss=0.008448, nmse(dB)=-16.2095 | val loss=0.010775, nmse(dB)=-14.9108 | 0.1s\n",
      "[735/1000] train loss=0.008442, nmse(dB)=-16.2120 | val loss=0.010644, nmse(dB)=-14.9653 | 0.2s\n",
      "[736/1000] train loss=0.008387, nmse(dB)=-16.2474 | val loss=0.010819, nmse(dB)=-14.8986 | 0.2s\n",
      "[737/1000] train loss=0.008338, nmse(dB)=-16.2848 | val loss=0.010722, nmse(dB)=-14.9629 | 0.1s\n",
      "[738/1000] train loss=0.008308, nmse(dB)=-16.3204 | val loss=0.010750, nmse(dB)=-14.8896 | 0.2s\n",
      "[739/1000] train loss=0.008315, nmse(dB)=-16.3063 | val loss=0.010877, nmse(dB)=-14.8624 | 0.1s\n",
      "[740/1000] train loss=0.008346, nmse(dB)=-16.2940 | val loss=0.010655, nmse(dB)=-14.9550 | 0.1s\n",
      "[741/1000] train loss=0.008345, nmse(dB)=-16.3121 | val loss=0.010699, nmse(dB)=-14.9328 | 0.2s\n",
      "[742/1000] train loss=0.008254, nmse(dB)=-16.3110 | val loss=0.010832, nmse(dB)=-14.8705 | 0.2s\n",
      "[743/1000] train loss=0.008232, nmse(dB)=-16.3584 | val loss=0.010756, nmse(dB)=-14.8887 | 0.2s\n",
      "[744/1000] train loss=0.008171, nmse(dB)=-16.4435 | val loss=0.010816, nmse(dB)=-14.8879 | 0.2s\n",
      "[745/1000] train loss=0.008142, nmse(dB)=-16.3988 | val loss=0.010888, nmse(dB)=-14.8537 | 0.2s\n",
      "[746/1000] train loss=0.008205, nmse(dB)=-16.3604 | val loss=0.010791, nmse(dB)=-14.8690 | 0.2s\n",
      "[747/1000] train loss=0.008200, nmse(dB)=-16.3247 | val loss=0.010787, nmse(dB)=-14.8884 | 0.2s\n",
      "[748/1000] train loss=0.008150, nmse(dB)=-16.3759 | val loss=0.011035, nmse(dB)=-14.7701 | 0.2s\n",
      "[749/1000] train loss=0.008173, nmse(dB)=-16.3719 | val loss=0.010739, nmse(dB)=-14.8968 | 0.2s\n",
      "[750/1000] train loss=0.008154, nmse(dB)=-16.3345 | val loss=0.010822, nmse(dB)=-14.8661 | 0.2s\n",
      "[751/1000] train loss=0.008142, nmse(dB)=-16.3881 | val loss=0.010940, nmse(dB)=-14.8394 | 0.2s\n",
      "[752/1000] train loss=0.008116, nmse(dB)=-16.4276 | val loss=0.010700, nmse(dB)=-14.9426 | 0.2s\n",
      "[753/1000] train loss=0.008226, nmse(dB)=-16.3273 | val loss=0.010756, nmse(dB)=-14.8990 | 0.2s\n",
      "[754/1000] train loss=0.008052, nmse(dB)=-16.4265 | val loss=0.010919, nmse(dB)=-14.8189 | 0.2s\n",
      "[755/1000] train loss=0.008130, nmse(dB)=-16.3846 | val loss=0.010809, nmse(dB)=-14.8780 | 0.2s\n",
      "[756/1000] train loss=0.008076, nmse(dB)=-16.4033 | val loss=0.010768, nmse(dB)=-14.9003 | 0.2s\n",
      "[757/1000] train loss=0.008157, nmse(dB)=-16.3599 | val loss=0.010854, nmse(dB)=-14.8577 | 0.2s\n",
      "[758/1000] train loss=0.008006, nmse(dB)=-16.4436 | val loss=0.011138, nmse(dB)=-14.7105 | 0.2s\n",
      "[759/1000] train loss=0.008074, nmse(dB)=-16.3907 | val loss=0.010797, nmse(dB)=-14.9003 | 0.2s\n",
      "[760/1000] train loss=0.008023, nmse(dB)=-16.4259 | val loss=0.010824, nmse(dB)=-14.8774 | 0.2s\n",
      "[761/1000] train loss=0.007998, nmse(dB)=-16.5225 | val loss=0.010993, nmse(dB)=-14.7930 | 0.2s\n",
      "[762/1000] train loss=0.008014, nmse(dB)=-16.4569 | val loss=0.010971, nmse(dB)=-14.8084 | 0.2s\n",
      "[763/1000] train loss=0.007978, nmse(dB)=-16.5073 | val loss=0.010718, nmse(dB)=-14.9064 | 0.2s\n",
      "[764/1000] train loss=0.007954, nmse(dB)=-16.4842 | val loss=0.010740, nmse(dB)=-14.9300 | 0.2s\n",
      "[765/1000] train loss=0.007915, nmse(dB)=-16.4637 | val loss=0.011055, nmse(dB)=-14.7564 | 0.2s\n",
      "[766/1000] train loss=0.008009, nmse(dB)=-16.4634 | val loss=0.010878, nmse(dB)=-14.8308 | 0.2s\n",
      "[767/1000] train loss=0.007947, nmse(dB)=-16.4924 | val loss=0.010794, nmse(dB)=-14.8968 | 0.2s\n",
      "[768/1000] train loss=0.007896, nmse(dB)=-16.5649 | val loss=0.010902, nmse(dB)=-14.8527 | 0.2s\n",
      "[769/1000] train loss=0.007933, nmse(dB)=-16.5062 | val loss=0.011067, nmse(dB)=-14.7202 | 0.2s\n",
      "[770/1000] train loss=0.007821, nmse(dB)=-16.5524 | val loss=0.010995, nmse(dB)=-14.7624 | 0.2s\n",
      "[771/1000] train loss=0.007818, nmse(dB)=-16.5863 | val loss=0.010758, nmse(dB)=-14.9129 | 0.2s\n",
      "[772/1000] train loss=0.008000, nmse(dB)=-16.4059 | val loss=0.010820, nmse(dB)=-14.8845 | 0.2s\n",
      "[773/1000] train loss=0.007852, nmse(dB)=-16.5584 | val loss=0.011116, nmse(dB)=-14.7244 | 0.2s\n",
      "[774/1000] train loss=0.007931, nmse(dB)=-16.5178 | val loss=0.010813, nmse(dB)=-14.8829 | 0.2s\n",
      "[775/1000] train loss=0.007884, nmse(dB)=-16.5026 | val loss=0.010841, nmse(dB)=-14.8456 | 0.2s\n",
      "[776/1000] train loss=0.007848, nmse(dB)=-16.5487 | val loss=0.011026, nmse(dB)=-14.7583 | 0.2s\n",
      "[777/1000] train loss=0.007850, nmse(dB)=-16.5034 | val loss=0.010996, nmse(dB)=-14.7802 | 0.2s\n",
      "[778/1000] train loss=0.007789, nmse(dB)=-16.5739 | val loss=0.010861, nmse(dB)=-14.8700 | 0.2s\n",
      "[779/1000] train loss=0.007782, nmse(dB)=-16.5412 | val loss=0.010902, nmse(dB)=-14.8381 | 0.2s\n",
      "[780/1000] train loss=0.007765, nmse(dB)=-16.5982 | val loss=0.011133, nmse(dB)=-14.6813 | 0.2s\n",
      "[781/1000] train loss=0.007833, nmse(dB)=-16.5041 | val loss=0.011109, nmse(dB)=-14.7160 | 0.2s\n",
      "[782/1000] train loss=0.007740, nmse(dB)=-16.6283 | val loss=0.010778, nmse(dB)=-14.9081 | 0.2s\n",
      "[783/1000] train loss=0.007704, nmse(dB)=-16.6039 | val loss=0.010834, nmse(dB)=-14.8589 | 0.2s\n",
      "[784/1000] train loss=0.007696, nmse(dB)=-16.6095 | val loss=0.011318, nmse(dB)=-14.5725 | 0.2s\n",
      "[785/1000] train loss=0.007845, nmse(dB)=-16.5259 | val loss=0.011191, nmse(dB)=-14.6299 | 0.2s\n",
      "[786/1000] train loss=0.007674, nmse(dB)=-16.6667 | val loss=0.010905, nmse(dB)=-14.8294 | 0.2s\n",
      "[787/1000] train loss=0.007718, nmse(dB)=-16.5934 | val loss=0.010938, nmse(dB)=-14.8281 | 0.2s\n",
      "[788/1000] train loss=0.007677, nmse(dB)=-16.6716 | val loss=0.010891, nmse(dB)=-14.8298 | 0.2s\n",
      "[789/1000] train loss=0.007655, nmse(dB)=-16.6428 | val loss=0.011040, nmse(dB)=-14.7577 | 0.2s\n",
      "[790/1000] train loss=0.007565, nmse(dB)=-16.7111 | val loss=0.011086, nmse(dB)=-14.7337 | 0.2s\n",
      "[791/1000] train loss=0.007668, nmse(dB)=-16.6244 | val loss=0.010881, nmse(dB)=-14.8371 | 0.2s\n",
      "[792/1000] train loss=0.007572, nmse(dB)=-16.7084 | val loss=0.011002, nmse(dB)=-14.7349 | 0.2s\n",
      "[793/1000] train loss=0.007571, nmse(dB)=-16.7439 | val loss=0.011189, nmse(dB)=-14.6625 | 0.2s\n",
      "[794/1000] train loss=0.007588, nmse(dB)=-16.6936 | val loss=0.010956, nmse(dB)=-14.7988 | 0.2s\n",
      "[795/1000] train loss=0.007621, nmse(dB)=-16.7138 | val loss=0.010809, nmse(dB)=-14.8701 | 0.2s\n",
      "[796/1000] train loss=0.007658, nmse(dB)=-16.5890 | val loss=0.010896, nmse(dB)=-14.8327 | 0.2s\n",
      "[797/1000] train loss=0.007587, nmse(dB)=-16.6788 | val loss=0.011163, nmse(dB)=-14.6735 | 0.2s\n",
      "[798/1000] train loss=0.007656, nmse(dB)=-16.6181 | val loss=0.011027, nmse(dB)=-14.7351 | 0.2s\n",
      "[799/1000] train loss=0.007601, nmse(dB)=-16.6744 | val loss=0.010850, nmse(dB)=-14.8459 | 0.2s\n",
      "[800/1000] train loss=0.007521, nmse(dB)=-16.7305 | val loss=0.010948, nmse(dB)=-14.8124 | 0.2s\n",
      "[801/1000] train loss=0.007471, nmse(dB)=-16.7798 | val loss=0.011016, nmse(dB)=-14.7636 | 0.2s\n",
      "[802/1000] train loss=0.007569, nmse(dB)=-16.6935 | val loss=0.011046, nmse(dB)=-14.7329 | 0.2s\n",
      "[803/1000] train loss=0.007558, nmse(dB)=-16.6847 | val loss=0.010939, nmse(dB)=-14.7871 | 0.2s\n",
      "[804/1000] train loss=0.007518, nmse(dB)=-16.7138 | val loss=0.011110, nmse(dB)=-14.6971 | 0.2s\n",
      "[805/1000] train loss=0.007385, nmse(dB)=-16.8356 | val loss=0.011138, nmse(dB)=-14.6742 | 0.2s\n",
      "[806/1000] train loss=0.007473, nmse(dB)=-16.7586 | val loss=0.011014, nmse(dB)=-14.7426 | 0.2s\n",
      "[807/1000] train loss=0.007523, nmse(dB)=-16.6755 | val loss=0.010963, nmse(dB)=-14.7911 | 0.2s\n",
      "[808/1000] train loss=0.007403, nmse(dB)=-16.8327 | val loss=0.011037, nmse(dB)=-14.7647 | 0.2s\n",
      "[809/1000] train loss=0.007473, nmse(dB)=-16.7309 | val loss=0.011040, nmse(dB)=-14.7514 | 0.2s\n",
      "[810/1000] train loss=0.007462, nmse(dB)=-16.7372 | val loss=0.011121, nmse(dB)=-14.6916 | 0.2s\n",
      "[811/1000] train loss=0.007383, nmse(dB)=-16.8092 | val loss=0.011116, nmse(dB)=-14.6965 | 0.2s\n",
      "[812/1000] train loss=0.007369, nmse(dB)=-16.8110 | val loss=0.011068, nmse(dB)=-14.7231 | 0.2s\n",
      "[813/1000] train loss=0.007324, nmse(dB)=-16.8884 | val loss=0.010926, nmse(dB)=-14.8015 | 0.2s\n",
      "[814/1000] train loss=0.007380, nmse(dB)=-16.8440 | val loss=0.011034, nmse(dB)=-14.7642 | 0.2s\n",
      "[815/1000] train loss=0.007370, nmse(dB)=-16.8448 | val loss=0.011233, nmse(dB)=-14.6519 | 0.2s\n",
      "[816/1000] train loss=0.007404, nmse(dB)=-16.7868 | val loss=0.010996, nmse(dB)=-14.7829 | 0.2s\n",
      "[817/1000] train loss=0.007283, nmse(dB)=-16.8901 | val loss=0.010924, nmse(dB)=-14.8090 | 0.2s\n",
      "[818/1000] train loss=0.007345, nmse(dB)=-16.8663 | val loss=0.010932, nmse(dB)=-14.8050 | 0.2s\n",
      "[819/1000] train loss=0.007390, nmse(dB)=-16.7898 | val loss=0.011036, nmse(dB)=-14.7550 | 0.2s\n",
      "[820/1000] train loss=0.007409, nmse(dB)=-16.7831 | val loss=0.011083, nmse(dB)=-14.7338 | 0.2s\n",
      "[821/1000] train loss=0.007221, nmse(dB)=-16.9004 | val loss=0.011059, nmse(dB)=-14.7498 | 0.2s\n",
      "[822/1000] train loss=0.007352, nmse(dB)=-16.8060 | val loss=0.011051, nmse(dB)=-14.7524 | 0.2s\n",
      "[823/1000] train loss=0.007318, nmse(dB)=-16.8246 | val loss=0.011124, nmse(dB)=-14.7028 | 0.2s\n",
      "[824/1000] train loss=0.007333, nmse(dB)=-16.8728 | val loss=0.011107, nmse(dB)=-14.7084 | 0.2s\n",
      "[825/1000] train loss=0.007358, nmse(dB)=-16.7948 | val loss=0.011023, nmse(dB)=-14.7548 | 0.2s\n",
      "[826/1000] train loss=0.007316, nmse(dB)=-16.8635 | val loss=0.010991, nmse(dB)=-14.7805 | 0.2s\n",
      "[827/1000] train loss=0.007293, nmse(dB)=-16.8641 | val loss=0.011170, nmse(dB)=-14.6856 | 0.2s\n",
      "[828/1000] train loss=0.007314, nmse(dB)=-16.8781 | val loss=0.011195, nmse(dB)=-14.6622 | 0.2s\n",
      "[829/1000] train loss=0.007320, nmse(dB)=-16.8495 | val loss=0.011161, nmse(dB)=-14.6779 | 0.2s\n",
      "[830/1000] train loss=0.007215, nmse(dB)=-16.9420 | val loss=0.011125, nmse(dB)=-14.7007 | 0.2s\n",
      "[831/1000] train loss=0.007415, nmse(dB)=-16.7483 | val loss=0.011061, nmse(dB)=-14.7386 | 1.3s\n",
      "[832/1000] train loss=0.007280, nmse(dB)=-16.8380 | val loss=0.011061, nmse(dB)=-14.7372 | 0.2s\n",
      "[833/1000] train loss=0.007161, nmse(dB)=-16.9878 | val loss=0.011212, nmse(dB)=-14.6473 | 0.2s\n",
      "[834/1000] train loss=0.007271, nmse(dB)=-16.8796 | val loss=0.011299, nmse(dB)=-14.5995 | 0.2s\n",
      "[835/1000] train loss=0.007231, nmse(dB)=-16.9112 | val loss=0.011252, nmse(dB)=-14.6327 | 0.2s\n",
      "[836/1000] train loss=0.007384, nmse(dB)=-16.7402 | val loss=0.011059, nmse(dB)=-14.7429 | 0.2s\n",
      "[837/1000] train loss=0.007242, nmse(dB)=-16.9002 | val loss=0.010983, nmse(dB)=-14.7761 | 0.2s\n",
      "[838/1000] train loss=0.007252, nmse(dB)=-16.8494 | val loss=0.011084, nmse(dB)=-14.7204 | 0.2s\n",
      "[839/1000] train loss=0.007205, nmse(dB)=-16.9559 | val loss=0.011136, nmse(dB)=-14.6936 | 0.2s\n",
      "[840/1000] train loss=0.007296, nmse(dB)=-16.8497 | val loss=0.011093, nmse(dB)=-14.7240 | 0.2s\n",
      "[841/1000] train loss=0.007213, nmse(dB)=-16.8998 | val loss=0.011001, nmse(dB)=-14.7669 | 0.2s\n",
      "[842/1000] train loss=0.007199, nmse(dB)=-16.9530 | val loss=0.010983, nmse(dB)=-14.7622 | 0.2s\n",
      "[843/1000] train loss=0.007252, nmse(dB)=-16.9208 | val loss=0.011002, nmse(dB)=-14.7729 | 0.2s\n",
      "[844/1000] train loss=0.007156, nmse(dB)=-16.9496 | val loss=0.011224, nmse(dB)=-14.6438 | 0.2s\n",
      "[845/1000] train loss=0.007190, nmse(dB)=-16.9056 | val loss=0.011212, nmse(dB)=-14.6469 | 0.2s\n",
      "[846/1000] train loss=0.007164, nmse(dB)=-16.9360 | val loss=0.011168, nmse(dB)=-14.6716 | 0.2s\n",
      "[847/1000] train loss=0.007120, nmse(dB)=-16.9700 | val loss=0.011143, nmse(dB)=-14.6895 | 0.2s\n",
      "[848/1000] train loss=0.007135, nmse(dB)=-16.9601 | val loss=0.011156, nmse(dB)=-14.6862 | 0.2s\n",
      "[849/1000] train loss=0.007101, nmse(dB)=-17.0053 | val loss=0.011075, nmse(dB)=-14.7358 | 0.2s\n",
      "[850/1000] train loss=0.007063, nmse(dB)=-17.0097 | val loss=0.011134, nmse(dB)=-14.7001 | 0.2s\n",
      "[851/1000] train loss=0.007171, nmse(dB)=-16.9525 | val loss=0.011140, nmse(dB)=-14.6881 | 0.2s\n",
      "[852/1000] train loss=0.007117, nmse(dB)=-16.9618 | val loss=0.011154, nmse(dB)=-14.6732 | 0.2s\n",
      "[853/1000] train loss=0.007138, nmse(dB)=-16.9467 | val loss=0.011214, nmse(dB)=-14.6390 | 0.2s\n",
      "[854/1000] train loss=0.007119, nmse(dB)=-16.9739 | val loss=0.011051, nmse(dB)=-14.7395 | 0.2s\n",
      "[855/1000] train loss=0.007127, nmse(dB)=-16.9206 | val loss=0.010945, nmse(dB)=-14.8023 | 0.2s\n",
      "[856/1000] train loss=0.007117, nmse(dB)=-16.9695 | val loss=0.010936, nmse(dB)=-14.8046 | 0.2s\n",
      "[857/1000] train loss=0.007158, nmse(dB)=-16.9325 | val loss=0.010999, nmse(dB)=-14.7690 | 0.2s\n",
      "[858/1000] train loss=0.007071, nmse(dB)=-17.0096 | val loss=0.011157, nmse(dB)=-14.6791 | 0.2s\n",
      "[859/1000] train loss=0.007140, nmse(dB)=-16.9821 | val loss=0.011346, nmse(dB)=-14.5684 | 0.2s\n",
      "[860/1000] train loss=0.007081, nmse(dB)=-16.9697 | val loss=0.011213, nmse(dB)=-14.6442 | 0.2s\n",
      "[861/1000] train loss=0.007017, nmse(dB)=-17.0429 | val loss=0.011132, nmse(dB)=-14.6873 | 0.2s\n",
      "[862/1000] train loss=0.007051, nmse(dB)=-17.0566 | val loss=0.011213, nmse(dB)=-14.6308 | 0.2s\n",
      "[863/1000] train loss=0.007042, nmse(dB)=-17.0449 | val loss=0.011337, nmse(dB)=-14.5609 | 0.2s\n",
      "[864/1000] train loss=0.007118, nmse(dB)=-16.9656 | val loss=0.011383, nmse(dB)=-14.5379 | 0.2s\n",
      "[865/1000] train loss=0.007158, nmse(dB)=-16.9161 | val loss=0.011333, nmse(dB)=-14.5717 | 0.2s\n",
      "[866/1000] train loss=0.007047, nmse(dB)=-17.0552 | val loss=0.011192, nmse(dB)=-14.6569 | 0.2s\n",
      "[867/1000] train loss=0.007123, nmse(dB)=-16.9151 | val loss=0.011068, nmse(dB)=-14.7333 | 0.2s\n",
      "[868/1000] train loss=0.007059, nmse(dB)=-16.9499 | val loss=0.011072, nmse(dB)=-14.7309 | 0.2s\n",
      "[869/1000] train loss=0.007084, nmse(dB)=-16.9602 | val loss=0.011195, nmse(dB)=-14.6561 | 0.2s\n",
      "[870/1000] train loss=0.007086, nmse(dB)=-16.9959 | val loss=0.011182, nmse(dB)=-14.6606 | 0.2s\n",
      "[871/1000] train loss=0.007101, nmse(dB)=-16.9477 | val loss=0.011102, nmse(dB)=-14.7070 | 0.2s\n",
      "[872/1000] train loss=0.007059, nmse(dB)=-17.0093 | val loss=0.011070, nmse(dB)=-14.7302 | 0.2s\n",
      "[873/1000] train loss=0.007004, nmse(dB)=-17.0383 | val loss=0.011025, nmse(dB)=-14.7590 | 0.2s\n",
      "[874/1000] train loss=0.007032, nmse(dB)=-17.0101 | val loss=0.011131, nmse(dB)=-14.6996 | 0.2s\n",
      "[875/1000] train loss=0.007043, nmse(dB)=-16.9889 | val loss=0.011337, nmse(dB)=-14.5791 | 0.2s\n",
      "[876/1000] train loss=0.007029, nmse(dB)=-17.0031 | val loss=0.011373, nmse(dB)=-14.5524 | 0.2s\n",
      "[877/1000] train loss=0.007068, nmse(dB)=-17.0203 | val loss=0.011255, nmse(dB)=-14.6165 | 0.2s\n",
      "[878/1000] train loss=0.006925, nmse(dB)=-17.1364 | val loss=0.011118, nmse(dB)=-14.6923 | 0.2s\n",
      "[879/1000] train loss=0.006978, nmse(dB)=-17.0845 | val loss=0.011071, nmse(dB)=-14.7247 | 0.2s\n",
      "[880/1000] train loss=0.006920, nmse(dB)=-17.1420 | val loss=0.011139, nmse(dB)=-14.6888 | 0.2s\n",
      "[881/1000] train loss=0.007050, nmse(dB)=-17.0400 | val loss=0.011330, nmse(dB)=-14.5784 | 0.2s\n",
      "[882/1000] train loss=0.007074, nmse(dB)=-16.9598 | val loss=0.011387, nmse(dB)=-14.5450 | 0.2s\n",
      "[883/1000] train loss=0.007052, nmse(dB)=-17.0327 | val loss=0.011292, nmse(dB)=-14.5972 | 0.2s\n",
      "[884/1000] train loss=0.007099, nmse(dB)=-16.8980 | val loss=0.011180, nmse(dB)=-14.6627 | 0.2s\n",
      "[885/1000] train loss=0.007059, nmse(dB)=-16.9920 | val loss=0.011146, nmse(dB)=-14.6855 | 0.2s\n",
      "[886/1000] train loss=0.007060, nmse(dB)=-16.9828 | val loss=0.011179, nmse(dB)=-14.6656 | 0.2s\n",
      "[887/1000] train loss=0.006927, nmse(dB)=-17.0753 | val loss=0.011199, nmse(dB)=-14.6523 | 0.2s\n",
      "[888/1000] train loss=0.006928, nmse(dB)=-17.1021 | val loss=0.011125, nmse(dB)=-14.6923 | 0.2s\n",
      "[889/1000] train loss=0.006970, nmse(dB)=-17.0743 | val loss=0.011086, nmse(dB)=-14.7106 | 0.2s\n",
      "[890/1000] train loss=0.006958, nmse(dB)=-17.0349 | val loss=0.011163, nmse(dB)=-14.6646 | 0.2s\n",
      "[891/1000] train loss=0.007007, nmse(dB)=-17.0433 | val loss=0.011280, nmse(dB)=-14.5986 | 0.2s\n",
      "[892/1000] train loss=0.006892, nmse(dB)=-17.1080 | val loss=0.011360, nmse(dB)=-14.5551 | 0.2s\n",
      "[893/1000] train loss=0.006978, nmse(dB)=-17.0657 | val loss=0.011321, nmse(dB)=-14.5840 | 0.2s\n",
      "[894/1000] train loss=0.006923, nmse(dB)=-17.0998 | val loss=0.011212, nmse(dB)=-14.6518 | 0.2s\n",
      "[895/1000] train loss=0.007008, nmse(dB)=-16.9678 | val loss=0.011105, nmse(dB)=-14.7136 | 0.2s\n",
      "[896/1000] train loss=0.006930, nmse(dB)=-17.0836 | val loss=0.011074, nmse(dB)=-14.7316 | 0.2s\n",
      "[897/1000] train loss=0.006946, nmse(dB)=-17.0678 | val loss=0.011114, nmse(dB)=-14.7099 | 0.2s\n",
      "[898/1000] train loss=0.006994, nmse(dB)=-17.0658 | val loss=0.011238, nmse(dB)=-14.6360 | 0.2s\n",
      "[899/1000] train loss=0.006950, nmse(dB)=-17.0726 | val loss=0.011300, nmse(dB)=-14.5970 | 0.2s\n",
      "[900/1000] train loss=0.006921, nmse(dB)=-17.1250 | val loss=0.011262, nmse(dB)=-14.6179 | 0.2s\n",
      "[901/1000] train loss=0.006987, nmse(dB)=-17.0265 | val loss=0.011235, nmse(dB)=-14.6327 | 0.2s\n",
      "[902/1000] train loss=0.006875, nmse(dB)=-17.1238 | val loss=0.011184, nmse(dB)=-14.6603 | 0.2s\n",
      "[903/1000] train loss=0.006960, nmse(dB)=-17.0213 | val loss=0.011093, nmse(dB)=-14.7140 | 0.2s\n",
      "[904/1000] train loss=0.006885, nmse(dB)=-17.1188 | val loss=0.011068, nmse(dB)=-14.7283 | 0.2s\n",
      "[905/1000] train loss=0.006923, nmse(dB)=-17.0787 | val loss=0.011073, nmse(dB)=-14.7253 | 0.2s\n",
      "[906/1000] train loss=0.006990, nmse(dB)=-17.0700 | val loss=0.011179, nmse(dB)=-14.6622 | 0.2s\n",
      "[907/1000] train loss=0.006890, nmse(dB)=-17.1036 | val loss=0.011299, nmse(dB)=-14.5906 | 0.2s\n",
      "[908/1000] train loss=0.006918, nmse(dB)=-17.1035 | val loss=0.011333, nmse(dB)=-14.5684 | 0.2s\n",
      "[909/1000] train loss=0.006980, nmse(dB)=-17.0569 | val loss=0.011217, nmse(dB)=-14.6352 | 0.2s\n",
      "[910/1000] train loss=0.006947, nmse(dB)=-17.0923 | val loss=0.011150, nmse(dB)=-14.6747 | 0.2s\n",
      "[911/1000] train loss=0.006938, nmse(dB)=-17.0753 | val loss=0.011137, nmse(dB)=-14.6839 | 0.2s\n",
      "[912/1000] train loss=0.006898, nmse(dB)=-17.0919 | val loss=0.011121, nmse(dB)=-14.6952 | 0.2s\n",
      "[913/1000] train loss=0.006964, nmse(dB)=-17.0345 | val loss=0.011162, nmse(dB)=-14.6716 | 0.2s\n",
      "[914/1000] train loss=0.006920, nmse(dB)=-17.0374 | val loss=0.011200, nmse(dB)=-14.6497 | 0.2s\n",
      "[915/1000] train loss=0.006895, nmse(dB)=-17.1096 | val loss=0.011208, nmse(dB)=-14.6448 | 0.2s\n",
      "[916/1000] train loss=0.006957, nmse(dB)=-17.0523 | val loss=0.011177, nmse(dB)=-14.6634 | 0.2s\n",
      "[917/1000] train loss=0.007020, nmse(dB)=-16.9821 | val loss=0.011163, nmse(dB)=-14.6716 | 0.2s\n",
      "[918/1000] train loss=0.006920, nmse(dB)=-17.0728 | val loss=0.011148, nmse(dB)=-14.6812 | 0.2s\n",
      "[919/1000] train loss=0.006956, nmse(dB)=-17.0558 | val loss=0.011158, nmse(dB)=-14.6760 | 0.2s\n",
      "[920/1000] train loss=0.006868, nmse(dB)=-17.1370 | val loss=0.011205, nmse(dB)=-14.6504 | 0.2s\n",
      "[921/1000] train loss=0.006911, nmse(dB)=-17.0892 | val loss=0.011242, nmse(dB)=-14.6292 | 0.2s\n",
      "[922/1000] train loss=0.006934, nmse(dB)=-17.0333 | val loss=0.011230, nmse(dB)=-14.6352 | 0.2s\n",
      "[923/1000] train loss=0.006889, nmse(dB)=-17.1337 | val loss=0.011174, nmse(dB)=-14.6652 | 0.2s\n",
      "[924/1000] train loss=0.006962, nmse(dB)=-17.0072 | val loss=0.011127, nmse(dB)=-14.6903 | 0.2s\n",
      "[925/1000] train loss=0.006885, nmse(dB)=-17.1056 | val loss=0.011108, nmse(dB)=-14.6989 | 0.2s\n",
      "[926/1000] train loss=0.006995, nmse(dB)=-17.0236 | val loss=0.011137, nmse(dB)=-14.6828 | 0.2s\n",
      "[927/1000] train loss=0.006817, nmse(dB)=-17.1967 | val loss=0.011177, nmse(dB)=-14.6610 | 0.2s\n",
      "[928/1000] train loss=0.006867, nmse(dB)=-17.1213 | val loss=0.011211, nmse(dB)=-14.6418 | 0.2s\n",
      "[929/1000] train loss=0.006937, nmse(dB)=-17.0615 | val loss=0.011236, nmse(dB)=-14.6274 | 0.2s\n",
      "[930/1000] train loss=0.006828, nmse(dB)=-17.1516 | val loss=0.011250, nmse(dB)=-14.6180 | 0.2s\n",
      "[931/1000] train loss=0.006866, nmse(dB)=-17.0742 | val loss=0.011260, nmse(dB)=-14.6103 | 0.2s\n",
      "[932/1000] train loss=0.006876, nmse(dB)=-17.1021 | val loss=0.011267, nmse(dB)=-14.6048 | 0.1s\n",
      "[933/1000] train loss=0.006863, nmse(dB)=-17.1556 | val loss=0.011288, nmse(dB)=-14.5912 | 0.2s\n",
      "[934/1000] train loss=0.006921, nmse(dB)=-17.0992 | val loss=0.011308, nmse(dB)=-14.5809 | 0.2s\n",
      "[935/1000] train loss=0.006941, nmse(dB)=-17.0473 | val loss=0.011277, nmse(dB)=-14.6012 | 0.2s\n",
      "[936/1000] train loss=0.006857, nmse(dB)=-17.1264 | val loss=0.011226, nmse(dB)=-14.6325 | 0.1s\n",
      "[937/1000] train loss=0.006896, nmse(dB)=-17.1180 | val loss=0.011193, nmse(dB)=-14.6526 | 0.2s\n",
      "[938/1000] train loss=0.006836, nmse(dB)=-17.1309 | val loss=0.011196, nmse(dB)=-14.6521 | 0.2s\n",
      "[939/1000] train loss=0.006971, nmse(dB)=-16.9753 | val loss=0.011219, nmse(dB)=-14.6396 | 0.2s\n",
      "[940/1000] train loss=0.006778, nmse(dB)=-17.2209 | val loss=0.011249, nmse(dB)=-14.6231 | 0.1s\n",
      "[941/1000] train loss=0.006866, nmse(dB)=-17.1083 | val loss=0.011264, nmse(dB)=-14.6150 | 0.2s\n",
      "[942/1000] train loss=0.006885, nmse(dB)=-17.1085 | val loss=0.011261, nmse(dB)=-14.6169 | 0.2s\n",
      "[943/1000] train loss=0.006966, nmse(dB)=-17.0194 | val loss=0.011244, nmse(dB)=-14.6262 | 0.2s\n",
      "[944/1000] train loss=0.006889, nmse(dB)=-17.0835 | val loss=0.011217, nmse(dB)=-14.6421 | 0.2s\n",
      "[945/1000] train loss=0.006902, nmse(dB)=-17.0956 | val loss=0.011193, nmse(dB)=-14.6558 | 0.2s\n",
      "[946/1000] train loss=0.006835, nmse(dB)=-17.1368 | val loss=0.011192, nmse(dB)=-14.6563 | 0.1s\n",
      "[947/1000] train loss=0.006926, nmse(dB)=-17.0791 | val loss=0.011191, nmse(dB)=-14.6572 | 0.1s\n",
      "[948/1000] train loss=0.006978, nmse(dB)=-16.9892 | val loss=0.011202, nmse(dB)=-14.6513 | 0.1s\n",
      "[949/1000] train loss=0.006932, nmse(dB)=-17.0719 | val loss=0.011226, nmse(dB)=-14.6378 | 0.2s\n",
      "[950/1000] train loss=0.006931, nmse(dB)=-17.0836 | val loss=0.011253, nmse(dB)=-14.6220 | 0.2s\n",
      "[951/1000] train loss=0.006815, nmse(dB)=-17.1499 | val loss=0.011267, nmse(dB)=-14.6142 | 0.2s\n",
      "[952/1000] train loss=0.006836, nmse(dB)=-17.1760 | val loss=0.011273, nmse(dB)=-14.6102 | 0.2s\n",
      "[953/1000] train loss=0.006887, nmse(dB)=-17.1059 | val loss=0.011269, nmse(dB)=-14.6127 | 0.2s\n",
      "[954/1000] train loss=0.006839, nmse(dB)=-17.1893 | val loss=0.011252, nmse(dB)=-14.6220 | 0.2s\n",
      "[955/1000] train loss=0.006964, nmse(dB)=-17.0232 | val loss=0.011233, nmse(dB)=-14.6326 | 0.2s\n",
      "[956/1000] train loss=0.006871, nmse(dB)=-17.0794 | val loss=0.011215, nmse(dB)=-14.6427 | 0.2s\n",
      "[957/1000] train loss=0.006868, nmse(dB)=-17.0846 | val loss=0.011209, nmse(dB)=-14.6460 | 0.2s\n",
      "[958/1000] train loss=0.006846, nmse(dB)=-17.1468 | val loss=0.011210, nmse(dB)=-14.6451 | 0.2s\n",
      "[959/1000] train loss=0.006812, nmse(dB)=-17.1841 | val loss=0.011215, nmse(dB)=-14.6426 | 0.2s\n",
      "[960/1000] train loss=0.006869, nmse(dB)=-17.1504 | val loss=0.011221, nmse(dB)=-14.6397 | 0.2s\n",
      "[961/1000] train loss=0.006812, nmse(dB)=-17.1684 | val loss=0.011230, nmse(dB)=-14.6348 | 0.2s\n",
      "[962/1000] train loss=0.006811, nmse(dB)=-17.1820 | val loss=0.011235, nmse(dB)=-14.6318 | 0.2s\n",
      "[963/1000] train loss=0.006837, nmse(dB)=-17.1097 | val loss=0.011241, nmse(dB)=-14.6288 | 0.2s\n",
      "[964/1000] train loss=0.006877, nmse(dB)=-17.1349 | val loss=0.011244, nmse(dB)=-14.6275 | 0.2s\n",
      "[965/1000] train loss=0.006807, nmse(dB)=-17.1866 | val loss=0.011250, nmse(dB)=-14.6236 | 0.2s\n",
      "[966/1000] train loss=0.006825, nmse(dB)=-17.1885 | val loss=0.011262, nmse(dB)=-14.6164 | 0.2s\n",
      "[967/1000] train loss=0.006871, nmse(dB)=-17.1105 | val loss=0.011269, nmse(dB)=-14.6126 | 0.2s\n",
      "[968/1000] train loss=0.006936, nmse(dB)=-17.0178 | val loss=0.011273, nmse(dB)=-14.6103 | 0.2s\n",
      "[969/1000] train loss=0.006860, nmse(dB)=-17.1121 | val loss=0.011273, nmse(dB)=-14.6103 | 0.2s\n",
      "[970/1000] train loss=0.006857, nmse(dB)=-17.1590 | val loss=0.011270, nmse(dB)=-14.6118 | 0.2s\n",
      "[971/1000] train loss=0.006866, nmse(dB)=-17.1140 | val loss=0.011263, nmse(dB)=-14.6154 | 0.2s\n",
      "[972/1000] train loss=0.006836, nmse(dB)=-17.0958 | val loss=0.011256, nmse(dB)=-14.6191 | 0.2s\n",
      "[973/1000] train loss=0.006896, nmse(dB)=-17.1440 | val loss=0.011260, nmse(dB)=-14.6164 | 0.2s\n",
      "[974/1000] train loss=0.006868, nmse(dB)=-17.1297 | val loss=0.011263, nmse(dB)=-14.6147 | 0.2s\n",
      "[975/1000] train loss=0.006942, nmse(dB)=-17.0817 | val loss=0.011264, nmse(dB)=-14.6144 | 0.2s\n",
      "[976/1000] train loss=0.006852, nmse(dB)=-17.1030 | val loss=0.011264, nmse(dB)=-14.6143 | 0.2s\n",
      "[977/1000] train loss=0.006889, nmse(dB)=-17.1140 | val loss=0.011266, nmse(dB)=-14.6128 | 0.2s\n",
      "[978/1000] train loss=0.006815, nmse(dB)=-17.1283 | val loss=0.011267, nmse(dB)=-14.6123 | 0.2s\n",
      "[979/1000] train loss=0.006853, nmse(dB)=-17.1264 | val loss=0.011266, nmse(dB)=-14.6133 | 0.2s\n",
      "[980/1000] train loss=0.006848, nmse(dB)=-17.1529 | val loss=0.011263, nmse(dB)=-14.6147 | 0.2s\n",
      "[981/1000] train loss=0.006836, nmse(dB)=-17.0940 | val loss=0.011261, nmse(dB)=-14.6159 | 0.2s\n",
      "[982/1000] train loss=0.006805, nmse(dB)=-17.1942 | val loss=0.011260, nmse(dB)=-14.6168 | 0.2s\n",
      "[983/1000] train loss=0.006865, nmse(dB)=-17.1325 | val loss=0.011258, nmse(dB)=-14.6175 | 0.2s\n",
      "[984/1000] train loss=0.006849, nmse(dB)=-17.1427 | val loss=0.011258, nmse(dB)=-14.6175 | 0.2s\n",
      "[985/1000] train loss=0.006862, nmse(dB)=-17.1368 | val loss=0.011257, nmse(dB)=-14.6183 | 0.2s\n",
      "[986/1000] train loss=0.006854, nmse(dB)=-17.1487 | val loss=0.011255, nmse(dB)=-14.6193 | 0.2s\n",
      "[987/1000] train loss=0.006793, nmse(dB)=-17.1584 | val loss=0.011253, nmse(dB)=-14.6203 | 0.2s\n",
      "[988/1000] train loss=0.006990, nmse(dB)=-17.0375 | val loss=0.011252, nmse(dB)=-14.6210 | 0.2s\n",
      "[989/1000] train loss=0.006933, nmse(dB)=-17.0534 | val loss=0.011249, nmse(dB)=-14.6227 | 0.2s\n",
      "[990/1000] train loss=0.006887, nmse(dB)=-17.0382 | val loss=0.011246, nmse(dB)=-14.6243 | 0.2s\n",
      "[991/1000] train loss=0.006895, nmse(dB)=-17.1092 | val loss=0.011245, nmse(dB)=-14.6255 | 0.2s\n",
      "[992/1000] train loss=0.006855, nmse(dB)=-17.1829 | val loss=0.011243, nmse(dB)=-14.6263 | 0.2s\n",
      "[993/1000] train loss=0.006847, nmse(dB)=-17.1479 | val loss=0.011242, nmse(dB)=-14.6269 | 0.2s\n",
      "[994/1000] train loss=0.006877, nmse(dB)=-17.0892 | val loss=0.011241, nmse(dB)=-14.6274 | 0.2s\n",
      "[995/1000] train loss=0.006848, nmse(dB)=-17.1071 | val loss=0.011240, nmse(dB)=-14.6279 | 0.2s\n",
      "[996/1000] train loss=0.006894, nmse(dB)=-17.1253 | val loss=0.011240, nmse(dB)=-14.6282 | 0.2s\n",
      "[997/1000] train loss=0.006909, nmse(dB)=-17.1051 | val loss=0.011240, nmse(dB)=-14.6283 | 0.2s\n",
      "[998/1000] train loss=0.006894, nmse(dB)=-17.0527 | val loss=0.011239, nmse(dB)=-14.6284 | 0.2s\n",
      "[999/1000] train loss=0.006856, nmse(dB)=-17.1564 | val loss=0.011239, nmse(dB)=-14.6285 | 0.2s\n",
      "[1000/1000] train loss=0.006849, nmse(dB)=-17.1339 | val loss=0.011239, nmse(dB)=-14.6285 | 0.2s\n",
      "\n",
      "=== Done ===\n",
      "Best val loss     : 0.010485\n",
      "Best val NMSE (dB): -15.0763\n",
      "Best epoch        : 468\n",
      "Total train time  : 2.83 min (169.7 sec)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "best_val_nmse = None\n",
    "best_epoch = -1\n",
    "\n",
    "t_train0 = time.time()  # ✅ 전체 학습 시작 시간\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    t0 = time.time()\n",
    "\n",
    "    tr_loss, tr_nmse = train_one_epoch(\n",
    "        model, train_loader, optimizer,\n",
    "        device=device, use_amp=True, grad_clip=1.0\n",
    "    )\n",
    "    va_loss, va_nmse = evaluate(model, val_loader, device=device)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    print(\n",
    "        f\"[{epoch:02d}/{epochs}] \"\n",
    "        f\"train loss={tr_loss:.6f}, nmse(dB)={tr_nmse:.4f} | \"\n",
    "        f\"val loss={va_loss:.6f}, nmse(dB)={va_nmse:.4f} | \"\n",
    "        f\"{dt:.1f}s\"\n",
    "    )\n",
    "\n",
    "    # ✅ best 체크포인트 저장 + best_nmse/epoch 기록\n",
    "    if va_loss < best_val_loss:\n",
    "        best_val_loss = va_loss\n",
    "        best_val_nmse = va_nmse\n",
    "        best_epoch = epoch\n",
    "\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"optimizer_state\": optimizer.state_dict(),\n",
    "                \"F_in\": F_in,\n",
    "                \"F_out\": F_out,\n",
    "                \"best_val_loss\": best_val_loss,   # (선택) 같이 저장\n",
    "                \"best_val_nmse\": best_val_nmse,   # (선택) 같이 저장\n",
    "            },\n",
    "            \"best_finetune.pt\"\n",
    "        )\n",
    "        print(\"  ↳ saved best_finetune.pt\")\n",
    "\n",
    "# ✅ 루프가 끝난 뒤 요약 출력 (스샷 느낌)\n",
    "total_sec = time.time() - t_train0\n",
    "print(\"\\n=== Done ===\")\n",
    "print(f\"Best val loss     : {best_val_loss:.6f}\")\n",
    "print(f\"Best val NMSE (dB): {best_val_nmse:.4f}\")\n",
    "print(f\"Best epoch        : {best_epoch}\")\n",
    "print(f\"Total train time  : {total_sec/60:.2f} min ({total_sec:.1f} sec)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d23882e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y abs mean: 0.4907627999782562\n",
      "y abs max : 0.9797839522361755\n",
      "y power   : 0.28452348709106445\n",
      "yhat abs mean: 0.48926734924316406\n",
      "yhat abs max : 1.0784201622009277\n",
      "yhat power   : 0.2785642147064209\n"
     ]
    }
   ],
   "source": [
    "# 채널-only: (ch, y)만 받음\n",
    "ch, y = next(iter(train_loader))\n",
    "\n",
    "print(\"y abs mean:\", y.abs().mean().item())\n",
    "print(\"y abs max :\", y.abs().max().item())\n",
    "print(\"y power   :\", (y**2).mean().item())\n",
    "\n",
    "with torch.no_grad():\n",
    "    yhat = model(ch.to(device))   # img 제거\n",
    "\n",
    "print(\"yhat abs mean:\", yhat.abs().mean().item())\n",
    "print(\"yhat abs max :\", yhat.abs().max().item())\n",
    "print(\"yhat power   :\", (yhat**2).mean().item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a090a4",
   "metadata": {},
   "source": [
    "# 데이터 입력 및 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c47fcab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== dataset sizes ===\n",
      "N(comm_frames): 100\n",
      "past_len      : 15\n",
      "len(ds)       : 85\n",
      "len(train_ds) : 63\n",
      "len(val_ds)   : 22\n",
      "len(train_loader): 2\n",
      "len(val_loader)  : 1\n",
      "\n",
      "=== one batch shapes ===\n",
      "ch : (32, 15, 2048)  -> (B,T,F_in)\n",
      "y  : (32, 2048)  -> (B,F_out)\n",
      "yhat: (32, 2048)  -> (B,F_out)\n",
      "this forward predicted vectors: 32 (=B)\n",
      "each vector predicts elements: 2048 (=F_out)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== dataset sizes ===\")\n",
    "print(\"N(comm_frames):\", len(comm_frames))\n",
    "print(\"past_len      :\", ds.past_len)\n",
    "print(\"len(ds)       :\", len(ds))\n",
    "print(\"len(train_ds) :\", len(train_ds))\n",
    "print(\"len(val_ds)   :\", len(val_ds))\n",
    "print(\"len(train_loader):\", len(train_loader))\n",
    "print(\"len(val_loader)  :\", len(val_loader))\n",
    "\n",
    "print(\"\\n=== one batch shapes ===\")\n",
    "ch, y = next(iter(train_loader))  # ✅ (ch, y)만 받기\n",
    "print(\"ch :\", tuple(ch.shape), \" -> (B,T,F_in)\")\n",
    "print(\"y  :\", tuple(y.shape), \" -> (B,F_out)\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    yhat = model(ch.to(device))   # ✅ model(ch)만 호출\n",
    "\n",
    "print(\"yhat:\", tuple(yhat.shape), \" -> (B,F_out)\")\n",
    "print(\"this forward predicted vectors:\", yhat.shape[0], \"(=B)\")\n",
    "print(\"each vector predicts elements:\", yhat.shape[1], \"(=F_out)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c792a69d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ffde29c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
