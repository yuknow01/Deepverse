{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "495970ff",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84911fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from deepverse import ParameterManager\n",
    "from deepverse.scenario import ScenarioManager\n",
    "from deepverse import Dataset\n",
    "\n",
    "from deepverse.visualizers import ImageVisualizer, LidarVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9982c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the configuration file\n",
    "scenario_name = \"DT31\"\n",
    "config_path = f\"scenarios/{scenario_name}/param/config.m\"\n",
    "\n",
    "# Initialize ParameterManager and load parameters\n",
    "param_manager = ParameterManager(config_path)\n",
    "params = param_manager.get_params()\n",
    "\n",
    "# Print the loaded parameters\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a749fe18",
   "metadata": {},
   "source": [
    "# data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cc84e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in params.items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095c6311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifiy the parameters\n",
    "# param_manager.params['scenes'] = list(range(0, 10))\n",
    "# param_manager.params['radar']['enabled'] = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e5fe96",
   "metadata": {},
   "source": [
    "# Generate a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b44c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead07fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac99b5c8",
   "metadata": {},
   "source": [
    "# Dataset Structure Analysis\n",
    "\n",
    "이 섹션에서는 Deepverse 라이브러리의 다양한 데이터셋(카메라, 라이다, 이동성, 통신, 레이더)의 데이터 형태와 구조를 상세히 검사합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01a40f3",
   "metadata": {},
   "source": [
    "## 1. Load and Inspect Camera Dataset\n",
    "\n",
    "카메라 데이터셋에 접근하여 형태, 데이터 타입, 구조를 검사합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641c9dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access camera_dataset from the Dataset object\n",
    "camera_dataset = dataset.camera_dataset\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CAMERA DATASET\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Type: {type(camera_dataset)}\")\n",
    "print(f\"Shape: {camera_dataset.shape if hasattr(camera_dataset, 'shape') else 'N/A'}\")\n",
    "print(f\"Data type: {camera_dataset.dtype if hasattr(camera_dataset, 'dtype') else type(camera_dataset)}\")\n",
    "print(f\"\\nFirst few elements:\")\n",
    "print(camera_dataset[:5] if hasattr(camera_dataset, '__getitem__') else camera_dataset)\n",
    "print(f\"\\nSize (bytes): {camera_dataset.nbytes if hasattr(camera_dataset, 'nbytes') else 'N/A'}\")\n",
    "print(f\"Number of dimensions: {camera_dataset.ndim if hasattr(camera_dataset, 'ndim') else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd444ccd",
   "metadata": {},
   "source": [
    "## 2. Load and Inspect Lidar Dataset\n",
    "\n",
    "라이다 데이터셋에 접근하여 차원, 배열 형태, 포인트 클라우드 구조를 검사합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46a2dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access lidar_dataset from the Dataset object\n",
    "lidar_dataset = dataset.lidar_dataset\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"LIDAR DATASET\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Type: {type(lidar_dataset)}\")\n",
    "print(f\"Shape: {lidar_dataset.shape if hasattr(lidar_dataset, 'shape') else 'N/A'}\")\n",
    "print(f\"Data type: {lidar_dataset.dtype if hasattr(lidar_dataset, 'dtype') else type(lidar_dataset)}\")\n",
    "print(f\"\\nFirst few elements:\")\n",
    "print(lidar_dataset[:5] if hasattr(lidar_dataset, '__getitem__') else lidar_dataset)\n",
    "print(f\"\\nSize (bytes): {lidar_dataset.nbytes if hasattr(lidar_dataset, 'nbytes') else 'N/A'}\")\n",
    "print(f\"Number of dimensions: {lidar_dataset.ndim if hasattr(lidar_dataset, 'ndim') else 'N/A'}\")\n",
    "if hasattr(lidar_dataset, 'shape') and len(lidar_dataset.shape) > 1:\n",
    "    print(f\"Total points: {np.prod(lidar_dataset.shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d026002b",
   "metadata": {},
   "source": [
    "## 3. Load and Inspect Mobility Dataset\n",
    "\n",
    "이동성 데이터셋에 접근하여 형태, 내용, 데이터 구성을 검사합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fa6108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access mobility_dataset from the Dataset object\n",
    "mobility_dataset = dataset.mobility_dataset\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MOBILITY DATASET\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Type: {type(mobility_dataset)}\")\n",
    "print(f\"Shape: {mobility_dataset.shape if hasattr(mobility_dataset, 'shape') else 'N/A'}\")\n",
    "print(f\"Data type: {mobility_dataset.dtype if hasattr(mobility_dataset, 'dtype') else type(mobility_dataset)}\")\n",
    "print(f\"\\nFirst few elements:\")\n",
    "print(mobility_dataset[:5] if hasattr(mobility_dataset, '__getitem__') else mobility_dataset)\n",
    "print(f\"\\nSize (bytes): {mobility_dataset.nbytes if hasattr(mobility_dataset, 'nbytes') else 'N/A'}\")\n",
    "print(f\"Number of dimensions: {mobility_dataset.ndim if hasattr(mobility_dataset, 'ndim') else 'N/A'}\")\n",
    "if hasattr(mobility_dataset, 'dtype') and hasattr(mobility_dataset.dtype, 'names'):\n",
    "    print(f\"Field names: {mobility_dataset.dtype.names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c552a4",
   "metadata": {},
   "source": [
    "## 4. Load and Inspect Communication Dataset\n",
    "\n",
    "통신 데이터셋에 접근하여 형태, 구조, 통신 관련 정보를 검사합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a8f30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access comm_dataset from the Dataset object\n",
    "comm_dataset = dataset.comm_dataset\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COMMUNICATION DATASET\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Type: {type(comm_dataset)}\")\n",
    "print(f\"Shape: {comm_dataset.shape if hasattr(comm_dataset, 'shape') else 'N/A'}\")\n",
    "print(f\"Data type: {comm_dataset.dtype if hasattr(comm_dataset, 'dtype') else type(comm_dataset)}\")\n",
    "print(f\"\\nFirst few elements:\")\n",
    "print(comm_dataset[:5] if hasattr(comm_dataset, '__getitem__') else comm_dataset)\n",
    "print(f\"\\nSize (bytes): {comm_dataset.nbytes if hasattr(comm_dataset, 'nbytes') else 'N/A'}\")\n",
    "print(f\"Number of dimensions: {comm_dataset.ndim if hasattr(comm_dataset, 'ndim') else 'N/A'}\")\n",
    "if hasattr(comm_dataset, 'dtype') and hasattr(comm_dataset.dtype, 'names'):\n",
    "    print(f\"Field names: {comm_dataset.dtype.names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af575d99",
   "metadata": {},
   "source": [
    "## 5. Load and Inspect Radar Dataset\n",
    "\n",
    "레이더 데이터셋에 접근하여 형태, 차원, 레이더 데이터 표현을 검사합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13781eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access radar_dataset from the Dataset object\n",
    "radar_dataset = dataset.radar_dataset\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RADAR DATASET\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Type: {type(radar_dataset)}\")\n",
    "print(f\"Shape: {radar_dataset.shape if hasattr(radar_dataset, 'shape') else 'N/A'}\")\n",
    "print(f\"Data type: {radar_dataset.dtype if hasattr(radar_dataset, 'dtype') else type(radar_dataset)}\")\n",
    "print(f\"\\nFirst few elements:\")\n",
    "print(radar_dataset[:5] if hasattr(radar_dataset, '__getitem__') else radar_dataset)\n",
    "print(f\"\\nSize (bytes): {radar_dataset.nbytes if hasattr(radar_dataset, 'nbytes') else 'N/A'}\")\n",
    "print(f\"Number of dimensions: {radar_dataset.ndim if hasattr(radar_dataset, 'ndim') else 'N/A'}\")\n",
    "if hasattr(radar_dataset, 'dtype') and hasattr(radar_dataset.dtype, 'names'):\n",
    "    print(f\"Field names: {radar_dataset.dtype.names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a668f9cd",
   "metadata": {},
   "source": [
    "## 6. Compare Dataset Structures\n",
    "\n",
    "모든 5개 데이터셋의 형태, 크기, 주요 특성을 비교 테이블로 표시합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af742c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive comparison table\n",
    "comparison_data = []\n",
    "\n",
    "datasets_info = [\n",
    "    (\"Camera\", camera_dataset),\n",
    "    (\"Lidar\", lidar_dataset),\n",
    "    (\"Mobility\", mobility_dataset),\n",
    "    (\"Communication\", comm_dataset),\n",
    "    (\"Radar\", radar_dataset)\n",
    "]\n",
    "\n",
    "for name, ds in datasets_info:\n",
    "    info = {\n",
    "        \"Dataset\": name,\n",
    "        \"Type\": str(type(ds).__name__),\n",
    "        \"Shape\": str(ds.shape) if hasattr(ds, 'shape') else \"N/A\",\n",
    "        \"Dimensions\": ds.ndim if hasattr(ds, 'ndim') else \"N/A\",\n",
    "        \"Data Type\": str(ds.dtype) if hasattr(ds, 'dtype') else str(type(ds)),\n",
    "        \"Size (MB)\": round(ds.nbytes / (1024 * 1024), 2) if hasattr(ds, 'nbytes') else \"N/A\",\n",
    "    }\n",
    "    comparison_data.append(info)\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"DATASET COMPARISON SUMMARY\")\n",
    "print(\"=\" * 100)\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655f0bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed statistics for each dataset\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"DETAILED STATISTICS FOR EACH DATASET\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for name, ds in datasets_info:\n",
    "    print(f\"\\n{name.upper()} Dataset Statistics:\")\n",
    "    print(\"-\" * 50)\n",
    "    if hasattr(ds, 'shape'):\n",
    "        print(f\"  Shape: {ds.shape}\")\n",
    "    if hasattr(ds, 'size'):\n",
    "        print(f\"  Total elements: {ds.size}\")\n",
    "    if hasattr(ds, 'dtype'):\n",
    "        print(f\"  Data type: {ds.dtype}\")\n",
    "        if hasattr(ds.dtype, 'names') and ds.dtype.names:\n",
    "            print(f\"  Fields: {ds.dtype.names}\")\n",
    "    if hasattr(ds, 'nbytes'):\n",
    "        print(f\"  Memory usage: {ds.nbytes / (1024 * 1024):.2f} MB\")\n",
    "    if isinstance(ds, np.ndarray):\n",
    "        print(f\"  Min value: {np.min(ds) if ds.size > 0 else 'N/A'}\")\n",
    "        print(f\"  Max value: {np.max(ds) if ds.size > 0 else 'N/A'}\")\n",
    "        print(f\"  Mean value: {np.mean(ds) if ds.size > 0 else 'N/A'}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
